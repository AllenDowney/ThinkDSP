% LaTeX source for ``Think DSP: Digital Signal Processing for Programmers''
% Copyright 2013  Allen B. Downey.

% License: Creative Commons Attribution-NonCommercial 3.0 Unported License.
% http://creativecommons.org/licenses/by-nc/3.0/
%

\documentclass[12pt]{book}
\usepackage[width=5.5in,height=8.5in,
  hmarginratio=3:2,vmarginratio=1:1]{geometry}

% for some of these packages, you might have to install
% texlive-latex-extra (in Ubuntu)

\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage{mathpazo}
\usepackage{url}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{makeidx}
\usepackage{setspace}
\usepackage{hevea}                           
\usepackage{upquote}
\usepackage{fancyhdr}
\usepackage[bookmarks]{hyperref}

\title{Think DSP}
\author{Allen B. Downey}

\newcommand{\thetitle}{Think DSP: Digital Signal Processing in Python}
\newcommand{\theversion}{0.5}

% these styles get translated in CSS for the HTML version
\newstyle{a:link}{color:black;}
\newstyle{p+p}{margin-top:1em;margin-bottom:1em}
\newstyle{img}{border:0px}

% change the arrows in the HTML version
\setlinkstext
  {\imgsrc[ALT="Previous"]{back.png}}
  {\imgsrc[ALT="Up"]{up.png}}
  {\imgsrc[ALT="Next"]{next.png}} 

\makeindex

\newif\ifplastex
\plastexfalse

\begin{document}

\frontmatter

\ifplastex

\else
\fi

\ifplastex
    \usepackage{localdef}
    \maketitle

\else

\newtheoremstyle{exercise}% name of the style to be used
  {\topsep}% measure of space to leave above the theorem. E.g.: 3pt
  {\topsep}% measure of space to leave below the theorem. E.g.: 3pt
  {}% name of font to use in the body of the theorem
  {0pt}% measure of space to indent
  {\bfseries}% name of head font
  {}% punctuation between head and body
  { }% space after theorem head; " " = normal interword space
  {}% Manually specify head

\theoremstyle{exercise}
\newtheorem{exercise}{Exercise}[chapter]

\input{latexonly}

\begin{latexonly}

\renewcommand{\blankpage}{\thispagestyle{empty} \quad \newpage}

% TITLE PAGES FOR LATEX VERSION

%-half title--------------------------------------------------
\thispagestyle{empty}

\begin{flushright}
\vspace*{2.0in}

\begin{spacing}{3}
{\huge Think DSP}\\
{\Large Digital Signal Processing in Python}
\end{spacing}

\vspace{0.25in}

Version \theversion

\vfill

\end{flushright}

%--verso------------------------------------------------------

\blankpage
\blankpage

%--title page--------------------------------------------------
\pagebreak
\thispagestyle{empty}

\begin{flushright}
\vspace*{2.0in}

\begin{spacing}{3}
{\huge Think DSP}\\
{\Large Digital Signal Processing in Python}
\end{spacing}

\vspace{0.25in}

Version \theversion

\vspace{1in}


{\Large
Allen B. Downey\\
}


\vspace{0.5in}

{\Large Green Tea Press}

{\small Needham, Massachusetts}

\vfill

\end{flushright}


%--copyright--------------------------------------------------
\pagebreak
\thispagestyle{empty}

Copyright \copyright ~2013 Allen B. Downey.


\vspace{0.2in}

\begin{flushleft}
Green Tea Press       \\
9 Washburn Ave \\
Needham MA 02492
\end{flushleft}

Permission is granted to copy, distribute, and/or modify this document
under the terms of the Creative Commons Attribution-NonCommercial 3.0 Unported
License, which is available at \url{http://creativecommons.org/licenses/by-nc/3.0/}.

\vspace{0.2in}

\end{latexonly}


% HTMLONLY

\begin{htmlonly}

% TITLE PAGE FOR HTML VERSION

{\Large \thetitle}

{\large Allen B. Downey}

Version \theversion

\vspace{0.25in}

Copyright 2012 Allen B. Downey

\vspace{0.25in}

Permission is granted to copy, distribute, and/or modify this document
under the terms of the Creative Commons Attribution-NonCommercial 3.0
Unported License, which is available at
\url{http://creativecommons.org/licenses/by-nc/3.0/}.

\setcounter{chapter}{-1}

\end{htmlonly}

\fi
% END OF THE PART WE SKIP FOR PLASTEX

\chapter{Preface}
\label{preface}

The premise of this book (and the other books in the {\it Think X}
series) is that if you know how to program, you can use that skill to
learn other things.  I am writing this book because I think the
conventional approach to digital signal processing is backward: most
books (and the classes that use them) present the material bottom-up,
starting with mathematical abstractions like phasors.

With a programming-based approach, I can go top-down, which means I
can present the most important ideas right away.  By the end of the
first chapter, you can decompose a sound into its harmonics, modify
the harmonics, and generate new sounds.

This is a work in progress, so comments are welcome.


Allen B. Downey \\*

Needham MA \\*

Allen B. Downey is a Professor of Computer Science at 
the Franklin W. Olin College of Engineering.



\section*{Contributor List}

If you have a suggestion or correction, please send email to 
{\tt downey@allendowney.com}.  If I make a change based on your
feedback, I will add you to the contributor list
(unless you ask to be omitted).
\index{contributors}

If you include at least part of the sentence the
error appears in, that makes it easy for me to search.  Page and
section numbers are fine, too, but not as easy to work with.
Thanks!

\small

\begin{itemize}

\item 

% ENDCONTRIB

\end{itemize}

\normalsize

\clearemptydoublepage

% TABLE OF CONTENTS
\begin{latexonly}

\tableofcontents

\clearemptydoublepage

\end{latexonly}

% START THE BOOK
\mainmatter


\chapter{Sounds and signals}
\label{sounds}

A {\bf signal} is a representation of a quantity that varies in time,
or space, or both.  That definition is pretty abstract, so let's start
with a concrete example, sound.  Sound is variation in air pressure.
A sound signal represents variations in air pressure over time.

A microphone is a device that measures these variations and generates
an electronic signal that represents sound.  A speaker is a device
that takes an electrical signal and produces sound.
Microphones and speakers are called {\bf transducers} because they
transduce, or convert, signals from one form to another.

This book is about signal processing, which includes processes for
synthesizing, transforming, and analyzing signals.  It focuses on
sound signals, but the same methods apply to other signals, like
electronic signals and mechanical vibration.

They also apply to signals that vary in space rather than time, like
elevation along a hiking trail.  And they apply to signals in more
than one dimension, like an image, which you can think of as a signal
that varies in two-dimensional space.  Or a movie, which is
a signal that varies in two-dimensional space {\it and} time.

But we start with simple one-dimensional sound.


\section{Periodic signals}

\begin{figure}
% violin.py
\centerline{\includegraphics[height=2.5in]{figs/tuning1.pdf}}
\caption{Segment from a recording of a tuning fork.}
\label{fig.tuning1}
\end{figure}

We'll also start with {\bf periodic signals}, which are signals that
repeat themselves after some period of time.  For example, if you
strike a tuning fork, it vibrates and generates sound.  If you record
that sound and plot the transduced signal, it looks like
Figure~\ref{fig.tuning1}.\footnote{I got this recording from
  \url{http://www.freesound.org/people/zippi1/sounds/18871/}.}

This signal is a sinusoid, which means it has the same shape as
the trigonometric sine function. 

You can see that this signal is periodic.  I chose the duration
to show three full periods, also known as {\bf cycles}.
The duration of each cycle is
about 2.3 ms.

The {\bf frequency} of a signal is the number of cycles
per second, which is the inverse of the period.
The units of frequency are cycles per second, or {\bf Hertz},
abbreviated ``Hz''.

The frequency of this signal is about 439 Hz, slightly lower than 440
Hz, which is the standard tuning pitch for orchestral music.  The
musical name of this note is A, or more specifically, A4.  If you are
not familiar with ``scientific pitch notation'', the suffix indicates
which octave the note is in.  A4 is the A above middle C.  A5 is one
octave higher.  See
\url{http://en.wikipedia.org/wiki/Scientific_pitch_notation}.

\begin{figure}
% violin.py
\centerline{\includegraphics[height=2.5in]{figs/violin1.pdf}}
\caption{Segment from a recording of a violin.}
\label{fig.violin1}
\end{figure}

A tuning fork generates a sinusoid because the vibration of the tines
is a form of simple harmonic motion.  Most musical instruments
produce periodic signals, but the shape of these signals is not
sinusoidal.  For example, Figure~\ref{fig.violin1} shows a segment
from a recording of a violin playing
Boccherini's String Quintet No. 5 in E, 3rd
movement.\footnote{The recording is from
  \url{http://www.freesound.org/people/jcveliz/sounds/92002/}.
I identified the piece using \url{http://www.musipedia.org}.}

% Parson's code: DUUDDUURDR

Again we can see that the signal is periodic, but the shape of the
signal is much more complex.  The shape of a periodic signal is called
the {\bf waveform}.  Most musical instruments produce waveforms more
complex than a sinusoid.  The shape of the waveform determines the
musical {\bf timbre}, which is our perception of the tone quality of the
sound.  People usually perceive complex waveforms as rich, warm and
more interesting than sinusoids.


\section{Spectral decomposition}

\begin{figure}
% violin.py
\centerline{\includegraphics[height=2.5in]{figs/violin2.pdf}}
\caption{Spectrum of a segment from the violin recording.}
\label{fig.violin2}
\end{figure}

The most important idea in this book is {\bf spectral decomposition},
which is the idea that a complex signal can be expressed as the sum of
simpler signals with different frequencies.

And the most important algorithm in this book is the {\bf discrete
  Fourier transform}, or {\bf DFT}, which takes a signal (a quantity
varying in time) and produces its {\bf spectrum}, which is the set of
sinusoids that add up to produce the signal.

For example, Figure~\ref{fig.violin2} shows the spectrum of the violin
recording in Figure~\ref{fig.violin1}.  The x-axis is the range of
frequencies that make up the signal.  The y-axis shows the strength of
each frequency component.

The lowest frequency component is called the {\bf fundamental
  frequency}.  The fundamental frequency of this signal is near 440 Hz
(actually a little lower, or ``flat'').

In this signal the fundamental frequency has the largest amplitude,
so it is also the {\bf dominant frequency}.

Normally the perceived pitch of a sound is determined by the
fundamental frequency, even if it is not dominant. 

The other spikes in the spectrum are at frequencies 880, 1320, 1760, and
2200, which are integer multiples of the fundamental.
These components are called {\bf harmonics} because they are
musically harmonious with the fundamental:

\begin{itemize}

\item 880 is the frequency of
A5, one octave higher than the fundamental.  

\item 1320 is approximately E6, which is a major fifth above A5.

\item 1760 is A6, two octaves above the fundamental. 

\item 2200 is approximately C$\sharp$7, which is a major third
above A6.

\end{itemize}

In other words, these harmonics make up the notes of an A major
chord, although not all in the same octave.  Some of them are only
approximate because the notes that make up Western music have been
adjusted for {\bf equal temperament} (see
 \url{http://en.wikipedia.org/wiki/Equal_temperament}).

Given the harmonics and their amplitudes, you can reconstruct the
signal (at least approximately) by adding up sinusoids.  Or, to
reconstruct the signal exactly, you can use the inverse DFT.  
Next we'll see how.


\section{Signals}

I wrote a Python module called {\tt thinkdsp} that contains
classes and function for working with signals and spectrums.
\footnote{In Latin the plural of ``spectrum'' is ``spectra'', but I
prefer to use standard English plurals.}  You can download
it from \url{http://think-dsp.com/thinkdsp.py}.

To represent signals, {\tt thinkdsp} provides a class named
{\tt Signal}, which is the parent class for several signal types,
including {\tt Sinusoid}, which represents both sine and cosine
signals.

{\tt thinkdsp} provides functions to create sine and cosine signals:

\begin{verbatim}
    cos_sig = thinkdsp.CosSignal(freq=440, amp=1.0, offset=0)
    sin_sig = thinkdsp.SinSignal(freq=880, amp=0.5, offset=0)
\end{verbatim}

{\tt freq} is frequency in Hz.  {\tt amp} is amplitude in arbitrary
units.  {\tt offset} is a {\tt phase offset} in radians.

The phase offset determines where in the period the signal starts
(that is, when {\tt t=0}).  For example, a cosine signal with {\tt
  offset=0} starts at $\cos 0$, which is 1.  With {\tt offset=pi/2} it
starts at $\cos \pi/2$, which is 0.
A sine signal with
{\tt offset=0} also starts at 0.  In fact,
a sine signal with {\tt offset=pi/2} is identical to a cosine
signal with {\tt offset=0}.

Signals have an \verb"__add__" method, so you can use the {\tt +}
operator to add them:

\begin{verbatim}
    mix = sin_sig + cos_sig
\end{verbatim}

The result is a {\tt SumSignal}, which represents the sum of two
or more signals.

A Signal is basically a Python representation of a mathematical
function.  Most signals are defined for all values of {\tt t},
from negative infinity to infinity.

But you can't do much with a
Signal until you evaluate it.
In this context, ``evaluate'' means taking a sequence of {\tt ts}
and computing the corresponding values of the signal, which I
call {\tt ys}.  I encapsulate {\tt ts} and {\tt ys} in an
object called a Wave.

A Wave represents a signal evaluated at a sequence of points in
time.  Each point in time is called a {\bf frame} (a term borrowed
from movies and video).  The measurement itself is called a
{\bf sample}, although ``frame'' and ``sample'' are sometimes
used interchangeably.

{\tt Signal} provides \verb"make_wave", which returns a new
Wave object:

\begin{verbatim}
    wave = mix.make_wave(duration=0.5, start=0, framerate=11025)
\end{verbatim}

{\tt duration} is the length of the Wave in seconds.  {\tt start} is
the start time, also in seconds.  {\tt framerate} is the (integer)
number of frames per second, which is also the number of samples
per second.

11,025 frames per second is one of several framerates commonly used in
audio file formats, including Waveform Audio File (WAV) and mp3. 

This example evaluates the signal from {\tt t=0} to {\tt t=0.5} at
5,513 equally-spaced frames (because 5,513 is half of 11,025).
The time between frames, or {\bf timestep}, is {\tt 1/11025} seconds, or
91 $\mu$s.

{\tt Wave} provides a {\tt plot} method that uses {\tt pyplot}.
You can plot the wave like this:

\begin{verbatim}
    wave.plot()
    pyplot.show()
\end{verbatim}

{\tt pyplot} is part of {\tt matplotlib}; it is included in many
Python distributions, or you might have to install it.

\begin{figure}
% example1.py
\centerline{\includegraphics[height=2.5in]{figs/example1.pdf}}
\caption{Segment from a mixture of two sinusoid signals.}
\label{fig.example1}
\end{figure}

At {\tt freq=440} there are 220 periods in 0.5 seconds, so this plot
would look like a solid block of color.  To zoom in on a small number
of periods, we can use {\tt segment}, which copies a segment of a Wave
and returns a new wave:

\begin{verbatim}
    period = mix.period
    segment = wave.segment(start=0, duration=period*3)
\end{verbatim}

{\tt period} is a property of a Signal; it returns the period in second.

{\tt start} and {\tt duration} are in seconds.  This example copies
the first three periods from {\tt mix}.  If we plot {\tt segment}, it
looks like Figure~\ref{fig.example1}.  This signal contains two
frequency components, so it is more complex than the signal from the
tuning fork, but less complex than the violin.


\section{Reading and writing Waves}

{\tt thinkdsp} provides \verb"read_wave", which reads a WAV
file and returns a Wave:

\begin{verbatim}
    violin_wave = thinkdsp.read_wave('violin1.wav')
\end{verbatim}

And {\tt Wave} provides {\tt write}, which writes a WAV file:

\begin{verbatim}
    wave.write(filename='example1.wav')
\end{verbatim}

You can listen to the Wave with any media player that plays WAV
files.  On UNIX systems, I use {\tt aplay}, which is simple, robust,
and included in many Linux distributions.  For Windows you might like
MicroWav, available from
\url{http://bellsouthpwp2.net/b/o/bobad/microwav.htm}.

{\tt thinkdsp} also provides \verb"play_wave", which runs
the media player as a subprocess:

\begin{verbatim}
    thinkdsp.play_wave(filename='example1.wav', player='aplay')
\end{verbatim}

It uses {\tt aplay} by default, but you can provide another player.


\section{Spectrums}

{\tt Wave} provides \verb"make_spectrum", which returns a
{\tt Spectrum}:

\begin{verbatim}
    spectrum = wave.make_spectrum()
\end{verbatim}

And {\tt Spectrum} provides {\tt plot}:

\begin{verbatim}
    spectrum.plot()
    thinkplot.show()
\end{verbatim}

{\tt thinkplot} is a module I wrote to provide wrappers around some of
the functions in {\tt pyplot}.  You can download it from
\url{http://think-dsp.com/thinkplot.py}.  It is also included in the
Git repository for this book (see Section~\ref{code}).

{\tt Spectrum} provides three methods that modify the spectrum:

\begin{itemize}

\item \verb"low_pass" applies a low-pass filter, which means that
  components above a given cutoff frequency are attenuated (that is,
  reduced in magnitude) by a factor.

\item \verb"high_pass" applies a high-pass filter, which means that
  it attenuates components below the cutoff.

\item \verb"band_stop" attenuates components in a the band of
frequencies between two cutoffs.

\end{itemize}

This example attenuates all frequencies above 600 by 99\%:

\begin{verbatim}
   spectrum.low_pass(cutoff=600, factor=0.01)
\end{verbatim}

Finally, you can convert a Spectrum back to a Wave:

\begin{verbatim}
    wave = spectrum.make_wave()
\end{verbatim}

At this point you know how to use many of the classes and functions in
{\tt thinkdsp}, and you are ready to do the exercises at the end of
the chapter.  In Chapter~\ref{harmonics} I explain more
about how these classes are implemented.



\section{Exercises}

\begin{exercise}
Read the thinkdsp documentation.
\end{exercise}

\begin{exercise}
Fork and clone the repo.
\end{exercise}

\begin{exercise}
The example code in this chapter is in {\tt example1.py}.  If you
run it, it should ...

Gradually increase the cutoff and listen...
\end{exercise}

\begin{exercise}
Run violin.py and listen.
\end{exercise}

\begin{exercise}
Create exercise1.py and copy example1.py

Record a WAV file, or download from ...

Use an audio editor to examine the wave

Find a section where the wave is periodic and plot a few periods.

Compute and plot the spectrum.
\end{exercise}

\begin{exercise}
Extract a 0.5-2 second segment with constant frequency.

Compute the spectrum.

Remove some of the harmonics, invert the transform and play the wave.
\end{exercise}

\begin{exercise}
Synthesize a wave by creating a spectrum with arbitrary harmonics,
inverting it, and listening.  What happens as you add frequency
components that are not multiples of the fundamental?
\end{exercise}

\begin{exercise}
This exercise asks you to write a function that simulates the
effect of sound transmission underwater.
This is a more open-ended exercise for ambitious readers.
It uses decibels, which you can read about at
\url{http://en.wikipedia.org/wiki/Decibel}.

First some background information: when sound travels through water,
high frequency components are absorbed more than low frequency
components.  In pure water, the absorption rate, expressed in decibels
per kilometer (dB/km), is proportional to frequency squared.

For example, if the absorption rate for frequency $f$ is 1 dB/km,
we expect the absorption rate for $2f$ to be 4 dB/km.  In other words,
doubling the frequency quadruples the absorption rate.

Over a distance of 10 kilometers, the $f$ component would be attenuated
by 10 dB, which corresponds to a factor of 10 in power, or a factor
of 3.162 in amplitude.  

Over the same distance, the $2f$ component would be attenuated by
40 dB, or a factor or 100 in amplitude.

Write a function that takes a Wave and returns a new Wave that contains
the same frequency components as the original, but where each
component is attenuated according to the absorption rate of water.
Apply this function to the violin recording to see what a violin
would sound like under water.

For more about the physics of sound transmission in water, see
``Underlying physics and mechanisms for the absorption of sound in
seawater'' at
\url{http://resource.npl.co.uk/acoustics/techguides/seaabsorption/physics.html}

\end{exercise}




\chapter{Harmonics}
\label{harmonics}


\section{Implementing Signals and Spectrums}

If you have done the exercises, you know how to use the classes and
methods in {\tt thinkdsp}.  Now let's see how they work.

We'll start with {\tt CosSignal} and {SinSignal}:

\begin{verbatim}
def CosSignal(freq=440, amp=1.0, offset=0):
    return Sinusoid(freq, amp, offset, func=numpy.cos)

def SinSignal(freq=440, amp=1.0, offset=0):
    return Sinusoid(freq, amp, offset, func=numpy.sin)
\end{verbatim}

These functions are just wrappers for {\tt Sinusoid}, which
is a kind of Signal:

\begin{verbatim}
class Sinusoid(Signal):
    
    def __init__(self, freq=440, amp=1.0, offset=0, func=numpy.sin):
        Signal.__init__(self)
        self.freq = freq
        self.amp = amp
        self.offset = offset
        self.func = func
\end{verbatim}

The parameters of \verb"__init__" are:

\begin{itemize}

\item {\tt freq}: frequency in cycles per second, or Hz.

\item {\tt amp}: amplitude.  The units of amplitude are arbitrary,
usually chosen so 1.0 corresponds to the maximum input from a
microphone or maximum output to a speaker.

\item {\tt offset}: where in its period the signal starts, at $t=0$.
In units of radians, for reasons I explain below.

\item {\tt func}: a Python function used
to evaluate the signal at a particular point in time.  It is
usually either {\tt numpy.sin} or {\tt numpy.cos}, yielding a sine or
cosine signal.

\end{itemize}

Like many \verb"__init__" methods, this one just tucks the
parameters away for future use.

The parent class of {\tt Sinusoid}, {\tt Signal}, provides \verb"make_wave":

\begin{verbatim}
    def make_wave(self, duration=1, start=0, framerate=11025):
        dt = 1.0 / framerate
        ts = numpy.arange(start, duration, dt)
        ys = self.evaluate(ts)
        return Wave(ys, framerate)
\end{verbatim}

{\tt start} and {\tt duration} are the start time and duration
in seconds.  {\tt framerate} is the number of frames (samples)
per second.

{\tt dt} is the time between samples, and {\tt ts} is the sequence
of sample times.

\verb"make_wave" invokes {\tt evaluate}, which has to be provided
by the child class of {\tt Signal}, in this case {\tt Sinusoid}.

{\tt evaluate} takes the sequence of samples times and returns an array of
corresponding quantities:

\begin{verbatim}
    def evaluate(self, ts):
        phases = PI2 * self.freq * ts + self.offset
        ys = self.amp * self.func(phases)
        return ys
\end{verbatim}

{\tt ts} and {\tt ys} are NumPy arrays.  I use NumPy and SciPy
throughout the book.  If you are familiar with these libraries,
that's great, but I will also explain as we go along.

Let's unwind this function one step at time:

\begin{enumerate}

\item {\tt self.freq} is frequency in cycles per second, and
each element of {\tt ts} a time in seconds, so their product is
the number of cycles since the start time.

\item {\tt PI2} is a constant that stores $2 \pi$.  Multiplying
by {\tt PI2} converts from cycles to {\bf phase}.  You can
think of phase as ``cycles since the start time'' except that the number
of cycles is in units of radians, so each cycle is $2 \pi$ radians.

\item {\tt self.offset} is the phase, in radians, at the start time.
  It has the effect of shifting the signal left or right in time.

\item If {\tt self.func} is {\tt sin} or {\tt cos}, the result is a
  value between $-1$ and $+1$.

\item Multiplying by {\tt self.amp} yields a signal that ranges from
  {\tt -self.amp} to {\tt +self.amp}.

\end{enumerate}

In math notation, {\tt evaluate} is written like this:

\[ A \cos (2 \pi f t + \phi) \]

where $A$ is amplitude, $f$ is frequency, $t$ is time, and $\phi$
is the phase offset.  It may seem like I wrote a lot of code
to evaluate one simple function, but as we will see, this code
provides a framework for dealing with all kinds of signals, not
just sinusoids.


\section{Computing the spectrum}

Given a Signal, we can compute a Wave.  Given a Wave, we can compute
a Spectrum.  {\tt Wave} provides \verb"make_spectrum", which returns
a new {\tt Spectrum} object.

\begin{verbatim}
    def make_spectrum(self):
        hs = numpy.fft.rfft(self.ys)
        return Spectrum(hs, self.framerate)
\end{verbatim}

\verb"make_spectrum" uses {\tt rfft}, which computes
the discrete Fourier transform using an algorithm called
{\bf Fast Fourier Transform} or FFT.

The result of {\tt fft} is a sequence of complex numbers, {\tt hs},
which is stored in a Spectrum.  There are two ways to think about
complex numbers:

\begin{itemize}

\item A complex number is the sum of a real part and an imaginary
part, often written $x + iy$, where $i$ is the imaginary unit, $\sqrt{-1}$.
You can think of $x$ and $y$ as Cartesian coordinates.

\item A complex number is also the product of a magnitude
and a complex exponential, $r e^{i \phi}$, where $r$ is the
{\bf magnitude} and $\phi$ is the
{\bf angle} in radians, also called the ``argument.''   You
can think of $r$ and $\phi$ as polar coordinates.

\end{itemize}

Each element of {\tt hs} corresponds to a
frequency component.  The magnitude of each element is proportional
to the amplitude of the corresponding component.
The angle of each element is the phase offset (relative to a cosine
signal).

{\tt NumPy} provides {\tt absolute}, which computes
the magnitude of a complex number, also called the ``absolute value,''
and {\tt angle}, which computes the angle.

Here is the definition of {\tt Spectrum}:

\begin{verbatim}
class Spectrum(object):

    def __init__(self, hs, framerate):
        self.hs = hs
        self.framerate = framerate

        n = len(hs)
        f_max = framerate / 2.0
        self.fs = numpy.linspace(0, f_max, n)

        self.amps = numpy.absolute(self.hs)
\end{verbatim}

Again, {\tt hs} is the result of the FFT and {\tt framerate}
is the number of frames per second.

The elements of {\tt hs} correspond to a sequence of frequencies, {\tt
  fs}, equally spaced from 0 to the maximum frequency, \verb"f_max".
The maximum frequency is {\tt framerate/2}, for reasons we'll see
soon.

Finally, {\tt amps} contains the magnitude of {\tt hs}, which
is proportional to the amplitude of the components.

{\tt Spectrum} also provides {\tt plot}, which plots the magnitude for each
frequency:

\begin{verbatim}
    def plot(self, low=0, high=None):
        thinkplot.Plot(self.fs[low:high], self.amps[low:high])
\end{verbatim}

{\tt low} and {\tt high} specify the slice of the Spectrum that
should be plotted.


\section{Other waveforms}

A sinusoid contains only one frequency component, so its DFT
has only one peak.  More complex waveforms, like the
violin recording, yield DFTs with many peaks.  In this section we
investigate the relationship between waveforms and their DFTs.

\begin{figure}
% example2.py
\centerline{\includegraphics[height=2.5in]{figs/triangle-200-1.pdf}}
\caption{Segment of a triangle signal at 200 Hz.}
\label{fig.triangle.200.1}
\end{figure}

The triangle waveform is like a straight-line version of a sinusoid.
Figure~\ref{fig.triangle.200.1} shows a triangle waveform with
frequency 200 Hz.

To generate a triangle wave, you can use {\tt thinkdsp.TriangleSignal}:

\begin{verbatim}
class TriangleSignal(Sinusoid):
    
    def evaluate(self, ts):
        cycles = self.freq * ts + self.offset / PI2
        frac, _ = numpy.modf(cycles)
        ys = numpy.abs(frac - 0.5)
        ys = normalize(unbias(ys), self.amp)
        return ys
\end{verbatim}

{\tt TriangleSignal} inherits \verb"__init__" from {\tt Sinusoid},
so it takes the same arguments: {\tt freq}, {\tt amp}, and {\tt offset}.

The only difference is {\tt evaluate}.  As we saw before,
{\tt ts} is the sequence of sample times where we want to
evaluate the signal.

There are lots of ways to generate a triangle wave.  The details
are not important, but here's how {\tt evaluate} works:

\begin{enumerate}

\item {\tt cycles} is the number of cycles since the start time.
{\tt numpy.modf} splits the number of cycles into the fraction
part, stored in {\tt frac}, and the integer part, which is ignored.
\footnote{Using an underscore as a variable name is a convention that
means, ``I don't intend to use this value.''}

\item {\tt frac} is a sequence that ramps from 0 to 1 with the given
frequency.  Subtracting
0.5 yields values between -0.5 and 0.5.  Taking the absolute value
yields a waveform that zig-zags between 0.5 and 0.

\item {\tt unbias} shifts the waveform down so it is centered at 0, then
{\tt normalize} scales it to the given amplitude, {\tt amp}.

\end{enumerate}

Here's the code that generates Figure~\ref{fig.triangle.200.1}:

\begin{verbatim}
    signal = thinkdsp.TriangleSignal(200)
    duration = signal.period*3
    segment = signal.make_wave(duration, framerate=10000)
    segment.plot()
\end{verbatim}


\section{Harmonics}

Next we can compute the spectrum of this waveform:

\begin{verbatim}
    wave = signal.make_wave(duration=0.5, framerate=framerate)
    spectrum = wave.make_spectrum()
    spectrum.plot()
\end{verbatim}

\begin{figure}
% example2.py
\centerline{\includegraphics[height=2.5in]{figs/triangle-200-2.pdf}}
\caption{Spectrum of a triangle signal at 200 Hz.}
\label{fig.triangle.200.2}
\end{figure}

Figure~\ref{fig.triangle.200.2} shows the result.  As expected, the
highest peak is at the fundamental frequency, 200 Hz, and there
are additional peaks at harmonic frequencies, which are integer
multiples of 200.

But one surprise is that there are no peaks at the even multiples:
400, 800, etc.  The harmonics of a triangle wave are all
odd multiples of the fundamental frequency, in this example
600, 1000, 1400, etc.

Another feature of this spectrum is the relationship between the
amplitude and frequency of the harmonics.  The amplitude of the
harmonics drops off in proportion to frequency squared.  For example
the frequency ratio of the first two harmonics (200 and 600 Hz) is 3, and the
amplitude ration is approximately 9.  The frequency ratio of the
next two harmonics (600 and 1000 Hz) is 1.7, and the amplitude ratio
is approximately $1.7^2 = 2.9$.

{\tt thinkdsp} also provides {\tt SquareSignal}, which represents
a square signal.  Here's the class definition:

\begin{verbatim}
class SquareSignal(Sinusoid):
    
    def evaluate(self, ts):
        cycles = self.freq * ts + self.offset / PI2
        frac, _ = numpy.modf(cycles)
        ys = self.amp * numpy.sign(unbias(frac))
        return ys
\end{verbatim}

Like {\tt TriangleSignal}, {\tt SquareSignal} inherits 
\verb"__init__" from {\tt Sinusoid}, so it takes the same
parameters.

And the {\tt evaluate} method is similar.  Again, {\tt cycles} is
the number of cycles since the start time, and {\tt frac} is the
fractional part, which ramps from 0 to 1 each period.

{\tt unbias} shifts {\tt frac} so it ramps from -0.5 to 0.5,
then {\tt numpy.sign} maps the negative values to -1 and the
positive values to 1.  Multiplying by {\tt amp} yields a square
wave that jumps between {\tt -amp} and {\tt amp}.

\begin{figure}
% example2.py
\centerline{\includegraphics[height=2.5in]{figs/square-100-1.pdf}}
\caption{Segment of a square signal at 100 Hz.}
\label{fig.square.100.1}
\end{figure}

\begin{figure}
% example2.py
\centerline{\includegraphics[height=2.5in]{figs/square-100-2.pdf}}
\caption{Spectrum of a square signal at 100 Hz.}
\label{fig.square.100.2}
\end{figure}

Figure~\ref{fig.square.100.1} shows three periods of a square
wave with frequency 100 Hz,
and Figure~\ref{fig.square.100.2} shows its spectrum.

Like a triangle wave, the square wave contains only odd harmonics,
which is why there are peaks at 300, 500, and 700 Hz, etc.
But the amplitude of the harmonics drops off more slowly.
Specifically, amplitude drops in proportion to frequency (not frequency
squared).


\section{Aliasing}

\begin{figure}
% example2.py
\centerline{\includegraphics[height=2.5in]{figs/triangle-1100-2.pdf}}
\caption{Spectrum of a triangle signal at 1100 Hz sampled at
10,000 frames per second.}
\label{fig.triangle.1100.2}
\end{figure}

I have a confession.  I chose the examples in the previous section
carefully,
to avoid showing you something confusing.  But now it's time to get
confused.

Figure~\ref{fig.triangle.1100.2} shows the spectrum of a triangle wave at 1100 Hz, sampled
at 10,000 frames per second.

As expected, there are peaks at 1100 and 3300 Hz, but the third
peak is at 4500, not 5500 Hz as expected.  There is a small fourth peak
at 2300, not 7700 Hz.  And if you look very closely, the peak that should
be at 9900 is actually at 100 Hz.  What's going on?

The fundamental problem is that when you evaluate the signal at
discrete points in time, you lose information about what happens
between samples.  For low frequency components, that's not a
problem, because you have lots of samples per period.

But if you sample a signal at 5000 Hz with 10,000 frames per second,
you only have two samples per period.  That's enough to measure the
frequency (it turns out), but it doesn't tell you much about
the shape of the signal.

If the frequency is higher, like the 5500 Hz component of the
triangle wave, things are worse: you don't even get the
frequency right.

To see why, let's generate cosine signals at 4500 and 5500 Hz,
and sample them at 10,000 frames per second:

\begin{verbatim}
    framerate = 10000

    signal = thinkdsp.CosSignal(4500)
    duration = signal.period*5
    segment = signal.make_wave(duration, framerate=framerate)
    segment.plot()

    signal = thinkdsp.CosSignal(5500)
    segment = signal.make_wave(duration, framerate=framerate)
    segment.plot()
\end{verbatim}

\begin{figure}
% example2.py
\centerline{\includegraphics[height=2.5in]{figs/aliasing-3.pdf}}
\caption{Cosine signals at 4500 and 5500 Hz, sampled at 10,000 frames
per second.}
\label{fig.aliasing-3}
\end{figure}

Figure~\ref{fig.aliasing-3} shows the result.  The
sampled waveform doesn't look very much like a sinusoid, but the
bigger problem is that the two waveforms are exactly the same!

When we sample a 5500 Hz signal at 10,000 frames per second, the
result is indistinguishable from a 4500 Hz signal.

For the same reason, a 7700 Hz signal is indistinguishable
from 2300 Hz, and a 9900 Hz is indistinguishable from 100 Hz.

This effect is called {\bf aliasing} because when the high frequency
signal is sampled, it disguises itself as a low frequency signal.

In this example, the highest frequency we can measure is 5000 Hz,
which is half the sampling rate.  Frequencies above 5000 Hz are folded
back below 5000 Hz, which is why this threshold is sometimes called
the ``folding frequency,'' but more often it is called the {\bf
  Nyquist frequency}.  See
\url{http://en.wikipedia.org/wiki/Nyquist_frequency}.

The folding pattern continues if the aliased frequency goes below
zero.  For example, the 5th harmonic of the 1100 Hz triangle wave is
at 12,100 Hz.  Folded at 5000 Hz, it would appear at -2100 Hz, but it
gets folded again at 0 Hz, back to 2100 Hz.  In fact, you can see a
small peak at 2100 Hz in Figure~\ref{fig.square.100.2}, and the next
one at 4300 Hz.


\section{Exercises}

\begin{exercise}
Listen to the various non-sinusoidal waveforms.
\end{exercise}

\begin{exercise}
Start with a sawtooth.  Compute the DFT.  Remove all harmonics above
the $i$th.
Compute the inverse DFT and see what it looks like.
Repeat for a range of values of $i$.
\end{exercise}

\begin{exercise}
Write a new Signal type, compute it's DFT and listen to it.  What
happens if the signal is discontinuous?  What if the signal is continuous
but the slope is discontinuous?
\end{exercise}

\begin{exercise}
Make a frequency-limited sawtooth wave and see what it looks like
and sounds like.
See \url{http://en.wikipedia.org/wiki/Sawtooth_wave}.

\begin{exercise}
What does a square wave sound like underwater?
\end{exercise}

\begin{exercise}
Sample an 1100 Hz triangle at 10000 frames per second and listen to it.
Can you hear the aliased harmonic?  Might help to play a sequence of
notes with increasing pitch.
\end{exercise}

\begin{exercise}
Compute the spectrum of an 1100 Hz square wave.
\end{exercise}


\end{exercise}


\chapter{Non-periodic signals}


\section{Chirp}

The signals we have worked with so far are periodic, which means
that they repeat forever.  It also means that their spectrums do
no vary in time.  In this chapter, we consider non-periodic signals,
which includes any signal whose frequency components change over time.
In other words, pretty much all sound signals.

We'll start with a {\bf chirp}, which is a signal with variable
frequency.  Here is a class that represents a chirp:

\begin{verbatim}
class Chirp(Signal):
    
    def __init__(self, start=440, end=880, amp=1.0):
        self.start = start
        self.end = end
        self.amp = amp
\end{verbatim}

{\tt start} and {\tt end} are the frequencies, in Hz, at the start
and end of the chirp.  {\tt amp} is amplitude.

In a linear chirp, the frequency increases linearly from {\tt start}
to {\tt end}.  Here is the function that evaluates the signal:

\begin{verbatim}
    def evaluate(self, ts):
        freqs = numpy.linspace(self.start, self.end, len(ts)-1)
        return self._evaluate(ts, freqs)
\end{verbatim}

{\tt ts} is the sequence of points in time where the signal should
be evaluated.  If the length of {\tt ts} is $n$, you can think of
it as a sequence of $n-1$ segments of time.  To compute the frequency
during each segment, we use {\tt numpy.linspace}.

\verb"_evaluate" is a helper function that does the rest of the
math:\footnote{Beginning a method name with an underscore makes it
``private,'' indicating that it is not part of the API that should
be used outside the class definition.}

\begin{verbatim}
    def _evaluate(self, ts, freqs):
        dts = numpy.diff(ts)
        dps = PI2 * freqs * dts
        phases = numpy.cumsum(dps)
        ys = self.amp * numpy.cos(phases)
        return ys
\end{verbatim}

{\tt numpy.diff} computes the difference between adjacent elements
of {\tt ts}, returning the length of each segment in seconds.  In
the usual case where the elements of {\tt ts} are equally spaced,
the {\tt dts} are all the same.

The next step is to figure out how much the phase changes during
each segment.  Since we know the frequency and duration of each
segment, the {\em change} in phase during each integral is
{\tt PI2 * freqs * dts}.

Given the changes in phase, {\tt numpy.cumsum} computes the total
phase at the end of each segment.  Finally {\tt numpy.cos}
maps from phase to amplitude.

It might not be obvious how this function works, so here's another
way to think about it.  When $f$ is constant, phase increases linearly
over time.  Mathematically:

\[ \phi = 2 \pi f t \]

If $f$ varies in time, we can find the relationship between phase
and the instantaneous value of $f$ by taking the time derivative
of both sides:

\[ \frac{d\phi}{dt} = 2 \pi f \]

In other words, frequency is the derivative of phase.  Or equivalently,
phase is the integral of frequency.  We can write the same
equation in differential form:

\[ d\phi = 2 \pi f dt \]

which looks a whole lot like this line from \verb"_evaluate":

\begin{verbatim}
        dps = PI2 * freqs * dts
\end{verbatim}

To find the total phase, you can imagine adding up the elements of
{\tt dps}, or if you like calculus, you can think of it as a
numerical solution of an integral.

Here's the code that creates and plays a chirp from 220 to 880 Hz, which
is two octaves from A3 to A5:

\begin{verbatim}
    signal = thinkdsp.Chirp(start=220, end=880)
    wave1 = signal.make_wave(duration=2)

    filename = 'chirp.wav'
    wave1.write(filename)
    thinkdsp.play_wave(filename)
\end{verbatim}

Before you go on, run this code and listen.


\section{Exponential chirp}

When you listen to this chirp, you might notice that the pitch
rises quickly at first and then slows down.
The chirp spans two octaves, but it only takes 2/3 s to span
the first octave, and twice as long to span the second.  

The reason is that our perception of pitch depends on the
logarithm of frequency.  As a result, the {\bf interval} we hear between
two notes depends on the {\em ratio} of their frequencies, not
the difference.  ``Interval'' is the musical term for the
perceived difference between two pitches.

For example, an octave is an interval where the ratio of two
pitches is 2.  So the interval from 220 to 440 is one octave
and the interval from 440 to 880 is also one octave.  The difference
in frequency is bigger, but the ratio is the same.

As a result, if frequency increases linearly, as in a linear
chirp, the perceived pitch increases logarithmically.

If you want the perceived pitch to increase linearly, the frequency
has to increase exponentially.  A signal with that shape is called
an {\bf exponential chirp}.

Here's the code that makes one:

\begin{verbatim}
class ExpoChirp(Chirp):
    
    def evaluate(self, ts):
        start, end = math.log10(self.start), math.log10(self.end)
        freqs = numpy.logspace(start, end, len(ts)-1)
        return self._evaluate(ts, freqs)
\end{verbatim}

Instead of {\tt numpy.linspace}, this version of evaluate uses
{\tt numpy.logspace}, which creates a series of frequencies
whose logarithms are equally spaced, which means that they increase
exponentially.

That's it; everything else is the same as Chirp.  Here's the code
that makes one:

\begin{verbatim}
    signal = thinkdsp.ExpoChirp(start=220, end=880)
    wave1 = signal.make_wave(duration=2)

    filename = 'expo_chirp.wav'
    wave1.write(filename)
    thinkdsp.play_wave(filename)
\end{verbatim}

Run this code and listen.  If you have a musical ear, this might
sound more like music than the linear chirp.


\section{Leakage}

\begin{figure}
% example3.py
\centerline{\includegraphics[height=2.5in]{figs/windowing1.pdf}}
\caption{Spectrum of (a) a periodic segment of a sinusoid, (b)
a non-periodic segment, (c) a tapered non-periodic segment.}
\label{fig.windowing1}
\end{figure}

In previous chapters, we used FFT to compute the spectrum of a wave.
Later, when we discuss how FFT works, we will learn that the algorithm
is based on the assumption that the signal is periodic.  In theory, we
should not use FFT on non-periodic signals, but in practice it happens
all the time.  But there are a few things you have to be careful about.

One common problem is dealing with discontinuities at the beginning
and end of a segment.  Because FFT assumes that the signal is periodic,
in a sense it connects the end of the segment back to the beginning
to make a loop.  If the end does not connect smoothly to the beginning,
the discontinuity creates additional frequency components in the
segment that are not in the signal.

As an example, let's start with a sine wave that contains only
one frequency component at 440 Hz.

\begin{verbatim}
    signal = thinkdsp.SinSignal(freq=440)
\end{verbatim}

If we select a segment that happens to be an integer multiple of
the period, the end of the segment connects smoothly with the
beginning, and FFT behaves well.

\begin{verbatim}
    duration = signal.period * 30
    wave = signal.make_wave(duration)
    spectrum = wave.make_spectrum()
\end{verbatim}

Figure~\ref{fig.windowing1}a shows the result.  As expected, there is
a single peak at 440 Hz.  But if the duration is not a multiple of the
period, bad things happen.  With {\tt duration = signal.period *
  30.25}, the signal starts at 0 and ends at 1.
Figure~\ref{fig.windowing1}b shows the spectrum of this segment.
Again, the peak is at 440 Hz, but now there are additional components
spread out from 240 to 640 Hz.  This spread is called ``spectral
leakage'', because some of the energy at the fundamental frequency
leaks into other frequencies.

In this case leakage happens because we are using FFT on a segment
that is not periodic.


\section{Windowing}

\begin{figure}
% example3.py
\centerline{\includegraphics[height=2.5in]{figs/windowing2.pdf}}
\caption{(a) Segment of a sinusoid, (b) Hamming window, (c) product
of the segment and the window.}
\label{fig.windowing2}
\end{figure}

We can reduce leakage by smoothing out the discontinuity between
the beginning and end of the segment, and one way to do that is
{\bf windowing}.

A ``window'' is a function designed to transform a non-periodic
segment into something that can pass for periodic.
Figure~\ref{fig.windowing2}a shows a segment where the end does not
connect smoothly to the beginning.

Figure~\ref{fig.windowing2}b shows a ``Hamming window'', one of the
more common window functions.  No window function is perfect, but some
can be shown to be optimal for different applications.

Figure~\ref{fig.windowing2}c shows the result of multiplying the
window by the original signal.  Where the window is close to 1, the
signal is unchanged.  Where the window is close to 0, the signal is
attenuated.  Because the window tapers at both ends, the end of the
segment connects smoothly to the beginning.

Figure~\ref{fig.windowing1}c shows the spectrum of the tapered signal.
Windowing has reduced leakage substantially, but not completely. 

Here's what the code looks like.  {\tt Wave} provides {\tt hamming},
which applies a Hamming window:

\begin{verbatim}
    def hamming(self):
        self.ys *= numpy.hamming(len(self.ys))
\end{verbatim}

{\tt numpy.hamming} computes the Hamming window with the given number
of elements.  {\tt numpy} provides functions to compute other window
functions, including {\tt bartlett}, {\tt blackman}, {\tt hanning},
and {\tt kaiser}.  One of the exercises at the end of this chapter
asks you to experiment with these other windows.


\section{Spectrum of a chirp}

\begin{figure}
% example3.py
\centerline{\includegraphics[height=2.5in]{figs/chirp1.pdf}}
\caption{Spectrum of a one-second one-octave chirp.}
\label{fig.chirp1}
\end{figure}

What do you think happens if you compute the spectrum of a chirp?
Here's an example that constructs a one-second one-octave chirp and
its spectrum:

\begin{verbatim}
    signal = thinkdsp.Chirp(start=220, end=440)
    wave = signal.make_wave(duration=1)
    spectrum = wave.make_spectrum()
\end{verbatim}

Figure~\ref{fig.chirp2} shows the result.  The spectrum shows
components at every frequency from 220 to 440 Hz with variations,
caused by leakage, that look a little like the Eye of Sauron.

The spectrum is approximately flat between 220 and 440 Hz, which
indicates that the signal spends equal time at each frequency in this
range.  Based on that observation, you should be able to guess what
the spectrum of an exponential chirp looks like.

The spectrum gives hints about the structure of the signal,
but it loses the relationship between frequency and time.
For example, we cannot tell by looking at this spectrum whether
the frequency went up or down, or both.


\section{Spectrogram}

\begin{figure}
% example3.py
\centerline{\includegraphics[height=2.5in]{figs/chirp2.pdf}}
\caption{Spectrogram of a one-second one-octave chirp.}
\label{fig.chirp2}
\end{figure}

To recover the relationship between frequency and time, we can break
the chirp into segments and plot the spectrum of each segment.  The
result is called a {\bf short-time Fourier transform} (STFT).

There are several ways to visualize a STFT, but the most common
is a {\bf spectrogram}, which shows time on the x-axis, and frequency
on the y-axis.  Each column in the spectrogram shows the spectrum of
a short segment, using color or grayscale to represent amplitude.

{\tt Wave} provides \verb"make_spectrogram", which returns a
{\tt Spectrogram} object:

\begin{verbatim}
    signal = thinkdsp.Chirp(start=220, end=440)
    wave = signal.make_wave(duration=1)
    spectrogram = wave.make_spectrogram(seg_length=512)
    spectrogram.plot(high=32)
\end{verbatim}

\verb"seg_length" is the number of samples in each segment.  I chose
512 because FFT is most efficient when the number of samples is a
power of 2.

Figure~\ref{fig.chirp2} shows the result.  The x-axis shows time from
0 to 1 seconds.  The y-axis shows frequency from 0 to 700 Hz.  I cut
off the top part of the spectrogram; the full range goes to 5012.5 Hz,
which is half of the framerate.

The spectrogram shows clearly that frequency increases linearly
over time.  Similarly, in the spectrogram of an exponential chirp, we
can see the shape of the exponential curve.

However, notice that the peak in each column is blurred across 2--3
cells.  This blurring reflects the limited resolution of the
spectrogram.


\section{The Gabor limit}

The {\bf time resolution} of the spectrogram is the duration of the
segments, which corresponds to the width of the cells in the
spectrogram.  Since each segment is 512 frames, and there are 11,025
frames per second, there are 0.046 seconds per segment.

The {\bf frequency resolution} is the frequency range between
components in the spectrum, which corresponds to the height of the
cells.  With 512 frames, we get 256 frequency components over a range
from 0 to 5012.5 Hz, so the range between components is 21.5 Hz.

More generally, if $n$ is the segment length, the spectrum contains
$n/2$ components.  If the framerate is $r$, the maximum frequency
in the spectrum is $r/2$.
So the time resolution is $n/r$ and the frequency resolution is 
$r/2$ divided by $n/2$, which is $r/n$.

Ideally we would like time resolution to be small, so we can see rapid
changes in frequency.  And we would like frequency resolution to be
small so we can see small changes in frequency.  But you can't have
both.  Notice that time resolution, $n/r$, is the inverse of frequency
resolution, $r/n$.  So if one gets smaller, the other gets bigger.

For example, if you double the segment length, you cut frequency
resolution in half (which is good), but you double time resolution
(which is bad).  Even increasing the framerate doesn't help.  You get
more samples to play with, but the range of frequencies increases at
the same time.

This tradeoff is called the ``Gabor limit'' and it is a fundamental
limitation of this kind of time-frequency analysis.


\section{Implementing spectrograms}

\begin{figure}
% example3.py
\centerline{\includegraphics[height=2.5in]{figs/windowing3.pdf}}
\caption{Overlapping Hamming windows.}
\label{fig.windowing3}
\end{figure}

Here is the {\tt Wave} method that computes spectrograms:

\begin{verbatim}
    def make_spectrogram(self, seg_length):
        n = len(self.ys)
        window = numpy.hamming(seg_length)

        start, end, step = 0, seg_length, seg_length / 2
        spec_map = {}

        while end < n:
            ys = self.ys[start:end] * window
            hs = numpy.fft.rfft(ys)

            t = (start + end) / 2.0 / self.framerate
            spec_map[t] = Spectrum(hs, self.framerate)

            start += step
            end += step

        return Spectrogram(spec_map, seg_length, window_func)
\end{verbatim}

\verb"seg_length" is the number of samples in each segment.
{\tt n} is the number of samples in the wave.  {\tt window}
is a Hamming window with the same length as the segments.

{\tt start} and {\tt end} are the slice indices that select
the segments from the wave.  {\tt step} is the offset between
segments.  Since {\tt step} is half of \verb"seg_length", the
segments overlap by half.  Figure~\ref{fig.windowing3} shows what
these overlapping windows look like.

Inside the while loop, we select a slice from the wave, multiply
by the window, and compute the FFT.  Then we construct a Spectrum
object and add it to \verb"spec_map" which is a map from the
midpoint of the segment in time to the Spectrum object.

Finally, the method constructs and returns a Spectrogram.  Here
is the definition of Spectrogram:

\begin{verbatim}
    def __init__(self, spec_map, seg_length):
        self.spec_map = spec_map
        self.seg_length = seg_length
\end{verbatim}

And {\tt Spectrogram} provides {\tt plot}, which generates a
pseudocolor plot:

\begin{verbatim}
    def plot(self, low=0, high=None):
        ts = self.times()
        fs = self.frequencies()[low:high]

        # copy amplitude from each spectrum into a column of the array
        size = len(fs), len(ts)
        array = numpy.zeros(size, dtype=numpy.float)

        # copy each spectrum into a column of the array
        for i, t in enumerate(ts):
            spectrum = self.spec_map[t]
            array[:,i] = spectrum.amps[low:high]

        thinkplot.pcolor(ts, fs, array)
\end{verbatim}

{\tt plot} uses {\tt times}, which the returns the midpoint of each
time segment in a sorted sequence, and {\tt frequencies}, which returns
the frequencies of the components in the spectrums.

{\tt array} is a numpy array that holds the amplitudes from the
spectrums, with one column for each point in time and one row
for each frequency.  The {\tt for} loop iterates through the times
and copies each spectrum into a column of the array.

Finally {\tt thinkplot.color} is a wrapper around {\tt pyplot.pcolor},
which generates the pseudocolor plot.

So that's how Spectrograms are implemented.


\section{Exercises}

\begin{exercise}
Write a class called {\tt SawtoothChirp} that extends {\tt Chirp}
and overrides {\tt evaluate} to generate a sawtooth waveform with
frequency that increases (or decreases) linearly.

Hint: combine the evaluate functions from {\tt Chirp} and {\tt
  SawtoothSignal}.

Draw a sketch of what you think the spectrogram of this signal
looks like, and then plot it.  The effect of aliasing should be
visually apparent, and if you listen carefully, you can hear it.
\end{exercise}

\begin{exercise}
Another way to generate a sawtooth chirp is to add up a harmonic
series of sinusoidal chirps.  Write another version of {\tt
  SawtoothChirp} that uses this method and plot the histogram.

If you truncate the harmonic series at the Nyquist frequency, you
should be able to avoid aliasing.
\end{exercise}


\begin{exercise}
In musical terminology, a ``glissando'' is a note that slides from one
pitch to another, so it is similar to a chirp.  A trombone player can
play a glissando by extending the trombone slide while blowing
continuously.  As the slide extends, the total length of the tube gets
longer, and the resulting pitch is inversely proportional to length.

Write a function that simulates a trombone glissando from C4 up to F4
and back down to C4.  C3 is 262 Hz; F3 is 349 Hz.

Assuming that the player moves the slide at a constant speed, how
does frequency vary with time?  Is a trombone glissando more like
a linear or exponential chirp?
\end{exercise}


\begin{exercise}
Try other window functions.
\end{exercise}

\begin{exercise}
Make a spectrogram of the clarinet glissando at the beginning of
Rhapsody in Blue.

% http://archive.org/details/rhapblue11924
\end{exercise}

\begin{exercise}
Make a recording of a series of vowel sounds and look at the spectrogram.
Can you identify different vowels?
\end{exercise}

%\begin{exercise}
%Compute the inverse spectrogram of an image and listen to it.
%Landscape images might work best.
%\end{exercise}


\chapter{Noise}

\begin{figure}
% noise.py
\centerline{\includegraphics[height=2.5in]{figs/whitenoise0.pdf}}
\caption{Waveform of uncorrelated uniform noise.}
\label{fig.whitenoise0}
\end{figure}

In English, ``noise'' means an unwanted or unpleasant sound.  In the
context of digital signal processing, it has two different senses:

\begin{enumerate}

\item As in English, it can mean an unwanted signal of any kind.  If
two signals interfere with each other, then for each signal the other
would be considered noise.

\item ``Noise'' also refers to a signal that contains components at
many frequencies, so it lacks the harmonic structure of the periodic
signals we saw in previous chapters.  

\end{enumerate}

This chapter is about noise in the second sense.  The simplest way
to understand noise is to generate it, and the simplest way to generate
it is uncorrelated uniform noise (UU noise).  ``Uniform'' means that the values
that make up the signal are drawn at random from a uniform distribution,
and ``uncorrelated'' means that each value is independent of the others.

Here's the code to generate some:

\begin{verbatim}
    duration = 0.5
    framerate = 11025
    n = framerate * duration
    ys = numpy.random.uniform(-1, 1, n)
    wave = thinkdsp.Wave(ys, framerate)
    wave.plot()
\end{verbatim}

The result is a wave with duration 0.5 seconds at 11,025
samples per second.  Each sample is drawn from a uniform distribution
between -1 and 1, which means that every value in that range is
equally likely.

If you play this wave, it sounds like the static you hear if you tune
a radio between channels.  Figure~\ref{fig.whitenoise0} shows what the
waveform looks like.  As expected, it looks pretty random.

\begin{figure}
% noise.py
\centerline{\includegraphics[height=2.5in]{figs/whitenoise1.pdf}}
\caption{Spectrum of uncorrelated uniform noise.}
\label{fig.whitenoise1}
\end{figure}

Now let's take a look at the spectrum.  Here's the code:

\begin{verbatim}
    spectrum = wave.make_spectrum()
    spectrum.plot_power()
\end{verbatim}

\verb"Spectrum.plot_power" is similar to \verb"Spectrum.plot",
except that it plots power density against frequency.  Power density
is the square of amplitude density, expressed in units of power per Hz.

Figure~\ref{fig.whitenoise1} shows the result.  Like the signal, the
spectrum looks pretty random.  And it is, but we have to be more
precise about the word ``random.''  There are at least three things we
might like to know about a random signal or its spectrum:

\begin{itemize}

\item Distribution: The distribution of a random signal is the set of
  possibly values and their probabilities.  For example, in the
  uniform noise signal, the set of values is the range from -1 to 1,
  and all values have the same probability.  An alternative is
  {\bf Gaussian noise}, where the set of values is the range from negative
  to positive infinity, but values near 0 are the most likely, with
  probability that drops off according to the Gaussian distribution or
  ``bell curve.''

\item Correlation: Is each value in the signal independent of the
  others, or are there dependencies between them?  In UU noise, each
  value is independent of the others, so knowing the value of the
  signal at one point in time provides no new information about the
  value at any other time.  An alternative is {\bf Brownian noise},
  where each value is the sum of the previous value and a random
  value.  So if the value of the signal is high at a particular point
  in time, we expect it to stay high for a least the next few values.
  And if it is low, we expect it to stay low.

\item Relationship between power and frequency: In the spectrum of UU
  noise, the power at all frequencies is drawn from the same
  distribution; that is, the is no relationship between power and
  frequency (or, if you like, the relationship is a constant).  An
  alternative is {\bf pink noise}, where power is inversely related
  to frequency; that is, the power at frequency $f$ is drawn from
  a distribution whose mean is proportional to $1/f$.

\end{itemize}


\section{Integrated spectrum}

For UU noise we can see the relationship between power and frequency
more clearly by looking at the {\bf integrated spectrum}, which
is a function of frequency, $f$, that shows the cumulative total power in
the spectrum up to $f$.

\begin{figure}
% noise.py
\centerline{\includegraphics[height=2.5in]{figs/whitenoise2.pdf}}
\caption{Integrated spectrum of uncorrelated uniform noise.}
\label{fig.whitenoise2}
\end{figure}


{\tt Spectrum} provides a method that computes the IntegratedSpectrum:

\begin{verbatim}
    def make_integrated_spectrum(self):
        cs = numpy.cumsum(self.power)
        cs /= cs[-1]
        return IntegratedSpectrum(cs, self.fs)
\end{verbatim}

{\tt self.power} is an array containing power, which is the square
of amplitude, for each frequency.
{\tt numpy.cumsum} computes the cumulative sum of the powers.
Dividing through by the last element normalizes the integrated
spectrum so it runs from 0 to 1.

The result is an IntegratedSpectrum.  Here is the class definition:

\begin{verbatim}
class IntegratedSpectrum(object):
    
    def __init__(self, cs, fs):
        self.cs = cs
        self.fs = fs
\end{verbatim}

Like Spectrum, IntegratedSpectrum provides \verb"plot_power", so
we can compute and plot the integrated spectrum like this:

\begin{verbatim}
    integ = spectrum.make_integrated_spectrum()
    integ.plot_power()
    thinkplot.show(xlabel='frequency (Hz)',
                   ylabel='cumulative power')
\end{verbatim}

The result, shown in Figure~\ref{fig.whitenoise2}, is a remarkably
straight line, which indicates that power at all
frequencies is constant, on average.  Noise with equal power
at all frequencies is called {\bf white noise} by analogy with light,
because an equal mixture
of light at all visible frequencies is white.



\section{Brownian noise}

\begin{figure}
% noise.py
\centerline{\includegraphics[height=2.5in]{figs/rednoise0.pdf}}
\caption{Waveform of Brownian noise.}
\label{fig.rednoise0}
\end{figure}

UU noise is uncorrelated, which means that each value does not depend
on the others.  An alternative is Brownian noise, in which each value
is the sum of the previous value and a random ``step.''

It is called ``Brownian'' by analogy with Brownian motion, in which a
particle suspended in a fluid moves apparently at random, due to
unseen interactions with the fluid.  Brownian motion is often
described using a {\bf random walk}, which is a mathematical model 
of a path where the distance between steps is characterized by a
random distribution.

The simplest way to generate Brownian noise is to generate an
uncorrelated signal and then compute it cumulative sum.

Here is a class definition that implements this algorithm:

\begin{verbatim}
class BrownianNoise(_Noise):

    def evaluate(self, ts):
        dys = numpy.random.uniform(-1, 1, len(ts))
        ys = numpy.cumsum(dys)
        ys = normalize(unbias(ys), self.amp)
        return ys
\end{verbatim}

We use {\tt numpy.random.uniform} to generate an uncorrelated signal
and {\tt numpy.cumsum} to compute the cumulative sum.  Since the
cumulative signal is likely to escape the range from -1 to 1, we
have to use {\tt unbias} to shift the mean to 0, and
{\tt normalize} to get the desired maximum amplitude.

Here's the code that generates a BrownianNoise object and plots the
waveform.

\begin{verbatim}
    signal = thinkdsp.BrownianNoise()
    wave = signal.make_wave(duration=0.5, framerate=11025)
    wave.plot()
\end{verbatim}

Figure~\ref{fig.rednoise0} shows the result.  The waveform
wanders up and down, but there is a clear correlation between
successive values.  When the amplitude is high, it tends to stay
high, and vice versa.

\begin{figure}
% noise.py
\centerline{\includegraphics[height=2.5in]{figs/rednoise3.pdf}}
\caption{Spectrum of Brownian noise on a log-log scale.}
\label{fig.rednoise3}
\end{figure}

If you plot the spectrum of Brownian noise, it doesn't look like
much.  Nearly all of the power is at the lowest frequencies; on a
linear scale, the higher frequency components are not visible.

To see the shape of the spectrum, we have to plot power density
and frequency on a log-log scale.  Here's the code:

\begin{verbatim}
    spectrum = wave.make_spectrum()
    spectrum.plot_power(low=1, linewidth=1, alpha=0.5)
    thinkplot.show(xlabel='frequency (Hz)',
                   ylabel='power density',
                   xscale='log',
                   yscale='log')
\end{verbatim}

In theory, we expect the result to be a straight line with slope -2.
To see why, it helps to know that if $H(f)$ is the Fourier transform
of a wave, $h(t)$, and $g(t)$ is the integral of $h(t)$, then the
Fourier transform of $g(t)$ is $H(f) / i 2 \pi f$.  In the denominator,
the factor of $f$ is the important part; it indicates
that integrating a waveform has the effect of a low-pass filter.
Each component is attenuated in proportion to its frequency.

Since power is related to the square of amplitude, dividing the
Fourier components by $f$ has the effect of dividing power by $f^2$.
Since we started with white noise, which has equal power at all
frequencies, we expect Brownian noise to have power at frequency $f$
proportional to $1/f^2$, on average.  In other words:
%
\[ P = k f^{-2} \]
%
with some unknown constant, $k$.  Taking the log of both sides yields:
%
\[ \log P = \log k -2 \log f \]
%
Which means that the result, in Figure~\ref{fig.rednoise3}, should be
a straight line with slope -2.  It is quite noisy, so we can't
be sure it is a straight line, but at least we can estimate
its slope.

Spectrum provides \verb"estimate_slope", which uses {\tt scipy}
to do linear regression, also known as a least squares fit:

\begin{verbatim}
    def estimate_slope(self):
        x = numpy.log(self.fs[1:])
        y = numpy.log(self.power[1:])
        t = scipy.stats.linregress(x,y)
        return t
\end{verbatim}

I discard the first component of the spectrum for two reasons: (1)
this component corresponds to $f=0$, and $\log 0$ is undefined,
and (2) the amplitude at $f=0$ indicates the mean value of the signal
(sometimes called the ``DC offset'' or ``bias.''  Since we unbiased
the signal, this component should be 0 anyway.

\verb"estimate_slope" returns the
result from {\tt scipy.stats.linregress} which is a tuple that
contains the estimated slope and intercept, coefficient of
determination, $R^2$, p-value, and standard error.  For now,
we only need the slope, which for this example is -1.8.

Note for readers of this draft: This result is close to the
theoretical value of -2, but not as close as I expected.  I am
working on finding the source of the discrepancy, but I would be
grateful for any hints.


\begin{verbatim}
\end{verbatim}

\begin{verbatim}
\end{verbatim}

\begin{verbatim}
\end{verbatim}


Coming up:

Pink noise.

Spectral density estimation.

Welch's method, discussion of amplitude, amplitude density, power
and decibels.

Spectrum of symbal crash, applause.

Estimate the spectrum of a long time series (stock market data?
astronomical data?)


\chapter{Pitch tracking}

Autocorrelation

\section{Spectrum of vowels}

\section{Spectrum of a piano}

\section{Music synthesis}

Additive synthesis.

Envelope generation.

\section{Convert music notation to a signal}

\section{Compute the spectrogram of an idealized performance}

\section{Compute the spectrogram of an actual performance}

\section{Pitch tracking algorithm}

Autocorrelation (or maybe this gets introduced in the noise chapter first?)

\section{Pitch shifting}

Auto-tune?


\chapter{Discrete cosine transform}

The topic of the next two chapters is the {\bf Discrete Cosine
  Transform} (DCT), which is used in MP3 and related formats for
compressing music, JPEG and similar formats for images, and the MPEG
family of formats for video.

DCT is similar in many ways to the discrete Fourier transform (DFT).
Once we learn how DCT works, it will be easier to explain DFT.

Here are the steps we will follow to get there:

\begin{enumerate}

\item We'll start with the synthesis problem: given a set of frequency
  components and their amplitudes, how can we construct a waveform?

\item Next we'll rewrite the synthesis problem using numpy arrays.
  This move is good for performance, and also provides insight
  into the analysis problem.

\item Next we'll look at the analysis problem: given a signal and a
  set of frequencies, how can we find the amplitude of each frequency
  component?  We'll start with a solution that is conceptually simple
  but slow.

\item Finally, we'll use some principles from linear algebra to find a
  more efficient algorithm.  If you already know linear algebra,
  that's great, but I will explain what you need as we go.

\end{enumerate}

Let's get started.


\section{Synthesis}

Suppose I give you a list of amplitudes and a list of frequencies,
and ask you to construct a signal that is the sum of these frequency
components.  Using objects in the {\tt thinkdsp} module, there is
a simple way to perform this operation, which is called {\bf synthesis}:

\begin{verbatim}
def synthesize1(amps, freqs, ts):
    components = [thinkdsp.CosSignal(freq, amp)
                  for amp, freq in zip(amps, freqs)]
    signal = thinkdsp.SumSignal(*components)

    ys = signal.evaluate(ts)
    return ys
\end{verbatim}

{\tt amps} is a list of amplitudes, {\tt freqs} is the list
of frequencies, and {\tt ts} is the sequence
of times where the signal should be evaluated.

{\tt components} is a list of {\tt CosSignal} objects, one for
each amplitude-frequency pair.  {\tt SumSignal} represents the
sum of these frequency components.

Finally, {\tt evaluate} computes the value of the signal at each
time in {\tt ts}.

We can test this function like this:

\begin{verbatim}
    amps = numpy.array([0.6, 0.25, 0.1, 0.05])
    freqs = [100, 200, 300, 400]
    framerate = 11025

    ts = numpy.linspace(0, 1, framerate)
    ys = synthesize1(amps, freqs, ts)
    wave = thinkdsp.Wave(ys, framerate)
    wave.play()
\end{verbatim}

This example makes a signal that contains a fundamental frequency at
100 Hz and three harmonics (100 Hz is a sharp G2).  It renders the
signal for one second at 11,025 frames per second and plays the
resulting wave.

Conceptually, synthesis is pretty simple.  But in this form it doesn't
help much with {\bf analysis}; that is, given the wave, identifying
the frequency components and their amplitudes.  To do that, we have
to take another approach.


\section{Synthesis with arrays}

\begin{figure}
\input{diagram}
\caption{Synthesis with arrays.}
\label{fig.synthesis}
\end{figure}

Here's another way to write {\tt synthesize}:

\begin{verbatim}
def synthesize2(amps, freqs, ts):
    args = numpy.outer(ts, freqs)
    M = numpy.cos(PI2 * args)
    ys = numpy.dot(M, amps)
    return ys
\end{verbatim}

This function looks very different, but it does the same thing.
Let's see how it works:

\begin{enumerate}

\item {\tt numpy.outer} computes the outer product of {\tt ts} and
  {\tt freqs}.  The result is an array with one row for each element
  of {\tt ts} and one column for each element of {\tt freqs}.  Each
  element in the array is the product of a frequency and a time, $f
  t$.

\item We multiply {\tt args} by $2 \pi$ and apply {\tt cos}, so each
  element of the result is $\cos (2 \pi f t)$.  Since the {\tt ts} run
  down the columns, each column contains a cosine signal at a
  particular frequency, evaluated at a sequence of times.

\item {\tt numpy.dot} computes a dot product.  In terms of linear
  algebra, we are multiplying a matrix, {\tt M}, by a vector, {\tt
    amps}.  Figure~\ref{fig.synthesis} is a diagram of this
  multiplication.  {\tt numpy.dot} multiplies each row of {\tt M} by
  {\tt amps}, element-wise, and then adds up the products.

\end{enumerate}

In the diagram, each row of the matrix, {\tt M}, corresponds to a time 
from 0.0 to 1.0 s; $t_k$ is the time of the $k$th row.
Each column corresponds to a frequency from
100 to 400 Hz; $f_j$ is the frequency of the $j$th column.

I have labeled the $k$th row with the letters $a$ through $d$; as an
example, the value of $a$ is $\cos [2 \pi (220) t_k]$.

The result of the dot product, {\tt ys}, is a vector with one element
for each row of {\tt M}.  The $k$th element, labeled $e$, is the sum
of products:
%
\[ e = 0.6 a + 0.25 b + 0.1 c + 0.05 d \]
%
And likewise with the other elements of {\tt ys}.  So each element
of {\tt y} is the sum of four frequency components, evaluated at
a point in time, and multiplied by the corresponding amplitudes.
And that's exactly what we wanted.  We can use the test code from
the previous section to
check that the two versions of {\tt synthesize} produce the same results.

\begin{verbatim}
    amps = numpy.array([0.6, 0.25, 0.1, 0.05])
    freqs = [100, 200, 300, 400]
    framerate = 11025
    ts = numpy.linspace(0, 1, framerate)
    ys1 = synthesize1(amps, freqs, ts)
    ys2 = synthesize2(amps, freqs, ts)
    print max(abs(ys1 == ys2))
\end{verbatim}

The biggest difference between {\tt ys1} and {\tt y2} is about {\tt
  1e-13}, which is about what we expect due to floating-point errors.

One note on linear algebra vocabulary: I am using ``matrix'' to refer
to a two-dimensional array, and ``vector'' for a one-dimensional array
or sequence.  To be a bit pedantic, it would be more correct to think
of matrices and vectors as abstract mathematical concepts, and {\tt
  numpy} arrays as one way (and not the only way) to represent them.

One advantage of linear algebra is that it provides concise notation
for operations on matrices and vectors.  For example, we could write
{\tt synthesize} like this:
%
\begin{eqnarray*}
M = \cos [2 \pi (t \otimes f)] \\
y = M a
\end{eqnarray*}
%
where $a$ is a vector of amplitudes,
$t$ is a vector of times, $f$ is a vector of frequencies, and
$\otimes$ is the symbol for the outer product of two vectors.


\section{Analysis}

Now we are ready to solve the analysis problem.  Suppose I give you
a wave and tell you that it is the sum of cosines with a given set
of frequencies.  How would you find the amplitude for each frequency
component?  In other words, given {\tt ys}, {\tt ts} and {\tt freqs},
can you recover {\tt amps}?

In terms of linear algebra, the first step is the same as for
synthesis: we compute $M = \cos[2 \pi (t \otimes f)]$.  Then we want
to find $a$ so that $y = M a$; in other words, we want to solve a
linear system.  {\tt numpy} provides {\tt linalg.solve}, which does
exactly that.

Here's what the code looks like:

\begin{verbatim}
def analyze1(ys, freqs, ts):
    args = numpy.outer(ts, freqs)
    M = numpy.cos(PI2 * args)
    amps = numpy.linalg.solve(M, ys)
    return amps
\end{verbatim}

The first two lines use {\tt ts} and {\tt freqs} to build the
matrix, {\tt M}.  Then {\tt numpy.linalg.solve} computes {\tt amps}.

But there's a catch.  In general we can only solve a system of linear
equations if the matrix is square; that is, the number of equations
(rows) is the same as the number of unknowns (columns).

In this example, we have only 4 frequencies, but we evaluated the
signal at 11,025 times.  So we have many more equations than unknowns.
That suggests that we should be able to recover $a$ using only
4 elements of {\tt ys}.  Here's what that looks like:

Using the values of {\tt ys}, {\tt freqs} and {\tt ts} from
the previous section, we can run {\tt analyze1} like this:

\begin{verbatim}
    n = len(freqs)
    amps2 = analyze1(ys[:n], freqs, ts[:n])
\end{verbatim}

And sure enough, we get

\begin{verbatim}
amps2 = [ 0.6   0.25  0.1   0.05]
\end{verbatim}

In this case, we know that the {\tt ys} were actually generated by
adding only 4 frequency components, so we can use any 4 values from
the wave array to recover {\tt amps}.  But in general if {\tt ys}
contains more than 4 elements, it is unlikely that we can analyze it
using only 4 frequencies.

We'll come back to this issue later, but first I want to address
a different problem -- this algorithm is slow.  Solving a linear
system of equations takes time proportional to $n^3$, where $n$ is
the number of columns in $M$.

It turns out that we can do better.


\section{Orthogonal matrixes}

One way to solve linear systems is by inverting matrixes.  The
inverse of a matrix $M$ is written $M^{-1}$, and it has the property
that $M^{-1}M = I$.  $I$ is the identity matrix, which has
the value 1 on all diagonal elements and 0 everywhere else.

So, to solve the equation $y = Ma$, we can multiply both sides by
$M^{-1}$, which yields:
%
\[ M^{-1}y = M^{-1} M a \]
%
On the right side, we can replace $M^{-1}M$ with $I$:
%
\[ M^{-1}y = I a \]
%
If we multiply $I$ by any vector $a$, the result is $a$, so  
%
\[ M^{-1}y = a \]
%
This implies that if we can compute $M^{-1}$ efficiently, we can solve
for $a$ with a simple matrix multiplication (using {\tt numpy.dot}).
That takes time proportional to $n^2$, which is much better than
$n^3$.

In general inverting a matrix is slow, but some special cases are
faster.  In particular, if $M$ is {\bf orthogonal}, the inverse of $M$
is just the transpose of $M$, written $M^T$.  And in {\tt numpy}
computing the transpose is usually a constant-time operation.  It
doesn't actually move the elements of the array; instead, it creates a
``view'' that changes the way the elements are accessed.

Again, a matrix is orthogonal
if its transpose is also
its inverse; that is, $M^T = M^{-1}$.  That implies that $M^TM = I$,
which means we can check whether a matrix is orthogonal by computing
$M^TM$.

So let's see what the matrix looks like in {\tt synthesize2}.  In 
the previous example, $M$ has 11,025 rows, so it might be a good idea
to work with a smaller example:

\begin{verbatim}
def test1():
    amps = numpy.array([0.6, 0.25, 0.1, 0.05])
    N = 4.0
    time_unit = 0.001
    ts = numpy.arange(N) / N * time_unit
    max_freq = N / time_unit / 2
    freqs = numpy.arange(N) / N * max_freq
    ys = synthesize2(amps, freqs, ts)
\end{verbatim}

{\tt amps} is the same vector of amplitudes we saw before.
Since we have 4 frequency components, we'll sample the signal
at 4 points in time.  That way, $M$ is square.

{\tt ts} is a vector of equally spaced sample times in the range from
0 to 1 time unit.  I chose the time unit to be 1 millisecond, but it
is an arbitrary choice, and we will see in a minute that it drops out
of the computation anyway.

Since the frame rate is $N$ samples per time unit, the Nyquist
frequency is \verb"N / time_unit / 2", which is 2000 Hz in this
example.  So {\tt freqs} is a vector of equally spaced frequencies
between 0 and 2000 Hz.

With these values of {\tt ts} and {\tt freqs}, the matrix, $M$, is:

\begin{verbatim}
[[ 1.     1.     1.     1.   ]
 [ 1.     0.707  0.    -0.707]
 [ 1.     0.    -1.    -0.   ]
 [ 1.    -0.707 -0.     0.707]]
\end{verbatim}

You might recognize 0.707 as an approximation of $\sqrt{2}/2$,
which is $\cos \pi/4$.  You also might notice that this matrix
is {\bf symmetric}, which means that the element at $(j, k)$ always
equals the element at $k, j$.  This implies that $M$ is its own
transpose; that is $M^T = M$.

But sadly, $M$ is not orthogonal.  If we compute $M^TM$, we get:

\begin{verbatim}
[[ 4.  1. -0.  1.]
 [ 1.  2.  1. -0.]
 [-0.  1.  2.  1.]
 [ 1. -0.  1.  2.]]
\end{verbatim}

And that's not the identity matrix.


\section{DCT-IV}

But if we choose {\tt ts} and {\tt freqs} carefully,
we can make $M$ orthogonal.  There are several ways to do it, which
is why there are several version of the discrete cosine transform (DCT).

One simple option is to shift {\tt
  ts} and {\tt freqs} by a half unit.  This version is called DCT-IV,
where ``IV'' is a roman numeral indicating that this is the fourth of
eight versions used often enough to deserve a name.

Here's an updated version of
{\tt test1}:

\begin{verbatim}
def test2()
    amps = numpy.array([0.6, 0.25, 0.1, 0.05])
    N = 4.0
    ts = (0.5 + numpy.arange(N)) / N
    freqs = (0.5 + numpy.arange(N)) / 2
    ys = synthesize2(amps, freqs, ts)
\end{verbatim}

If you compare this to the previous version, you'll notice
two changes.  First, I added 0.5 to {\tt ts} and {\tt freqs}.
Second, I cancelled out \verb"time_units", which simplifies
the expression for {\tt freqs}.

With these values, $M$ is

\begin{verbatim}
[[ 0.981  0.831  0.556  0.195]
 [ 0.831 -0.195 -0.981 -0.556]
 [ 0.556 -0.981  0.195  0.831]
 [ 0.195 -0.556  0.831 -0.981]]
\end{verbatim}

And $M^TM$ is

\begin{verbatim}
[[ 2.  0.  0.  0.]
 [ 0.  2. -0.  0.]
 [ 0. -0.  2. -0.]
 [ 0.  0. -0.  2.]]
\end{verbatim}

Some of the off-diagonal elements are displayed as -0, which means
that the floating-point representation is a small negative number.  So
this matrix is very close to $2I$, which means $M$ is almost
orthogonal; it's just off by a factor of 2.  And for our purposes,
that's good enough.

Because $M$ is symmetric and (almost) orthogonal, the inverse of $M$
is just $M/2$.  Now we can write a more efficient version of {\tt
  analyze}:

\begin{verbatim}
def analyze2(ys, freqs, ts):
    args = numpy.outer(ts, freqs)
    M = numpy.cos(PI2 * args)
    amps = numpy.dot(M, ys) / 2
    return amps
\end{verbatim}

Instead of using {\tt numpy.linalg.solve}, we just multiply
by $M/2$.

Putting it all together, we can write an implementation of
DCT-IV:

\begin{verbatim}
def dct_iv(ys):
    N = len(ys)
    ts = (0.5 + numpy.arange(N)) / N
    freqs = (0.5 + numpy.arange(N)) / 2
    args = numpy.outer(ts, freqs)
    M = numpy.cos(PI2 * args)
    amps = numpy.dot(M, ys) / 2
    return amps
\end{verbatim}

Again, {\tt ys} is the wave array.  We don't have to pass
{\tt ts} and {\tt freqs} as parameters; \verb"dct_iv" can
figure them out based on {\tt N}, the length of {\tt ys}.

We can test \verb"dct_iv" like this

\begin{verbatim}
    amps = numpy.array([0.6, 0.25, 0.1, 0.05])
    N = 4.0
    ts = (0.5 + numpy.arange(N)) / N
    freqs = (0.5 + numpy.arange(N)) / 2
    ys = synthesize2(amps, freqs, ts)

    amps2 = dct_iv(ys)
    print max(abs(amps - amps2))
\end{verbatim}

Starting with {\tt amps}, we synthesize a wave array, then use
\verb"dct_iv" to see if we can recover the amplitudes.  The biggest
difference between {\tt amps} and {\tt amps2} is about {\tt 1e-16},
which is what we expect with 64-bit floating point arithmetic.


\section{Inverse DCT}

Finally, notice that {\tt analyze2} and {\tt synthesize2} are almost
identical.  The only difference is that {\tt analyze2} divides the
result by 2.  We can use this insight to compute the inverse DCT:

\begin{verbatim}
def inverse_dct_iv(amps):
    return dct_iv(amps) * 2
\end{verbatim}

\verb"inverse_dct_iv" takes the vector of amplitudes and returns
the wave array, {\tt ys}.  We can confirm that it works by starting
with {\tt amps}, applying \verb"inverse_dct_iv" and \verb"dct_iv",
and testing that we get back what we started with.

\begin{verbatim}
    amps = [0.6, 0.25, 0.1, 0.05]
    ys = inverse_dct_iv(amps)
    amps2 = dct_iv(ys)
    print max(abs(amps - amps2))
\end{verbatim}

Again, the biggest difference is about {\tt 1e-16}.


\section{Summary}

This chapter explores the relationship between the synthesis problem
and the analysis problem.  By writing the synthesis problem in the
form of matrix operations, we derive an efficient algorithm for computing
the DCT.

This algorithm is based on a matrix, $M$, that is orthogonal and
symmetric, so it has the unusual property that the inverse of $M$ is
$M$ (within a factor of two, anyway).  As a result, the function we
wrote to compute DCT-IV also computes the inverse DCT.

For the analysis problem, we started with a solution that
takes time proportional to $n^3$ and improved it to take time
proportional to $n^2$.  It turns out that there is another optimization
that get the run time down to $n \log n$.  That algorithm is implemented
in {\tt scipy}, so we will use it in the next chapter.  And then in
Chapter~\ref{} we will see how it works.

The code from this chapter is available from
\url{http://think-dsp.com/example4.py}.





\section{Exercises}

\begin{exercise}
Test the algorithmic complexity of {\tt analyze1}, {\tt analyze2}
and {\tt scipy.fftpack.dct}.
\end{exercise}


\chapter{Using the DCT}

In the previous chapter we derived the DCT and wrote a simple
implementation of DCT-IV.  I chose DCT-IV because it is the
easiest to explain, but in practice it is more common to use
DCT-II and its inverse, DCT-III.  And unlike DCT-IV, the more
common versions are available in {\tt scipy}.


\appendix

\chapter{Cumulative Distribution Functions}

This appendix is a modified version of a chapter from
{\it Think Stats}, by Allen B. Downey, also published by
O'Reilly Media.

The goal of this chapter is to explain the {\bf cumulative
distribution function}, or {\bf CDF}.
But before we get start, it might help to 
talk about percentiles and percentile rank.
\index{cumulative distribution function}
\index{CDF}


\section{Percentiles}
\index{percentile rank}

If you have taken a standardized test, you probably got your
results in the form of a raw score and a {\bf percentile rank}.
In this context, the percentile rank is the fraction of people who
scored lower than you (or the same).  So if you are ``in the 90th
percentile,'' you did as well as or better than 90\% of the people who
took the exam.

Here's how you could compute the percentile rank of a value,
\verb"your_score", relative to the scores in the sequence {\tt
  scores}:
%
\begin{verbatim}
def PercentileRank(scores, your_score):
    count = 0
    for score in scores:
        if score <= your_score:
            count += 1

    percentile_rank = 100.0 * count / len(scores)
    return percentile_rank
\end{verbatim}
%
% see score_example.py
%
For example, if the scores in the sequence were 55, 66, 77, 88 and 99,
and you got the 88, then your percentile rank would be {\tt 100 * 4 / 5}
which is 80.

If you are given a value, it is easy to find its percentile rank; going
the other way is slightly harder.  If you are given a percentile rank
and you want to find the corresponding value, one option is to
sort the values and search for the one you want:
%
\begin{verbatim}
def Percentile(scores, percentile_rank):
    scores.sort()
    for score in scores:
        if PercentileRank(scores, score) >= percentile_rank:
            return score
\end{verbatim}

The result of this calculation is a {\bf percentile}.  For example,
the 50th percentile is the value with percentile rank 50.  In the
distribution of exam scores, the 50th percentile is 77.
\index{percentile}

This implementation of {\tt Percentile} is not very efficient.  We
will see how to do better soon.



\section{Cumulative distribution functions}
\index{cumulative distribution function}
\index{CDF}

\newcommand{\CDF}{\mathrm{CDF}}

Now that we understand percentiles, we are ready to tackle the
CDF, which is a function that
maps values to their percentile rank in a distribution.

The CDF is a function of $x$, which is any value that might appear
in the distribution.  To evaluate $\CDF(x)$ for a particular value of
$x$, we compute the fraction of the values in the sample less than (or
equal to) $x$.

Here's what that looks like as a function that takes a sample,
{\tt t}, and a value, {\tt x}:
%
\begin{verbatim}
def Cdf(t, x):
    count = 0.0
    for value in t:
        if value <= x:
            count += 1.0

    prob = count / len(t)
    return prob
\end{verbatim}

This function should look familiar; it is almost identical to {\tt
  PercentileRank}, except that the result is in a probability in the
range 0--1 rather than a percentile rank in the range 0--100.

As an example, suppose a sample has the values \{1, 2, 2, 3, 5\}.
Here are some values from its CDF:

\[ CDF(0) = 0  \]

\[ CDF(1) = 0.2 \]

\[ CDF(2) = 0.6 \]

\[ CDF(3) = 0.8 \]

\[ CDF(4) = 0.8 \]

\[ CDF(5) = 1 \]

We can evaluate the CDF for any value of $x$, not just
values that appear in the sample.
If $x$ is less than the smallest value in the sample, $\CDF(x)$ is 0.
If $x$ is greater than the largest value, $\CDF(x)$ is 1.

\begin{figure}
% cumulative.py
\centerline{\includegraphics[height=2.5in]{figs/example_cdf.pdf}}
\caption{Example of a CDF.}
\label{example_cdf}
\end{figure}

Figure~\ref{example_cdf} is a graphical representation of this CDF.
The CDF of a sample is a step function.  In the following sections we
will see distributions whose CDFs are more general mathematical
functions.


\section{Representing CDFs}
\index{{\tt cdf.py}@{\tt Cdf.py}}
\index{Cdf object}

I have written a module called
{\tt thinkstats2.py} that provides classes and functions used in
{\it Think Stats}.  You can download it from \url{}.  It is also
included in the code distributed with this book.

{\tt thinkstats2.py} provides a class named
{\tt Cdf} that represents CDFs.  

Cdfs are implemented with two sorted lists: {\tt xs}, which contains
the values, and {\tt ps}, which contains the probabilities.  The
most important methods Cdfs provide are:

\begin{description}

\item[{\tt Prob(x)}:] Given a value $x$, computes the probability $p = \CDF(x)$.

\item[{\tt Value(p)}:] Given a probability $p$, computes the
corresponding value, $x$; that is, the inverse CDF of $p$.

\end{description}

Because {\tt xs} and {\tt ps} are sorted, these operations use the
bisection algorithm, which is efficient.  The run time is proportional
to the logarithm of the number of values.
\index{bisection algorithm}

The Cdf module provides several functions for making Cdfs, including
{\tt MakeCdfFromList}, which takes a sequence of values
and returns their Cdf.

\section{thinkplot.py}

{\tt thinkplot.py} provides functions named {\tt Cdf} and
{\tt Cdfs} that plot Cdfs as lines.
\index{{\tt myplot.py}}

Cdf also provides {\tt Render}, which returns two lists, {\tt xs} and
{\tt ps}, suitable for plotting the CDF.  Because the CDF is a
step function, these lists have two elements for each unique
value in the distribution.

The distributions we have used so far are called {\bf
  empirical distributions} because they are based on empirical
observations, which are necessarily finite samples.

The alternative is a {\bf continuous distribution}, which is
characterized by a CDF that is a continuous function (as opposed to a
step function).  Many real world phenomena can be approximated by
continuous distributions.

\section{The exponential distribution}
\index{exponential distribution}
\index{distribution!exponential}

I'll start with the exponential distribution because it is
easy to work with.  In the real world, exponential distributions
come up when we look at a series of events and measure the
times between events, which are called {\bf interarrival times}.
If the events are equally likely to occur at any time, the distribution
of interarrival times tends to look like an exponential distribution.
\index{interarrival time}

The CDF of the exponential distribution is:
%
\[ \CDF(x) = 1 - e^{-\lambda x} \]
%
The parameter, $\lambda$, determines the shape of the
distribution.  Figure~\ref{expo_cdf} shows what this CDF looks like with
$\lambda = 2$.
\index{parameter}


\begin{figure}
% continuous.py
\centerline{\includegraphics[height=2.5in]{figs/expo_cdf.pdf}}
\caption{CDF of exponential distribution.}
\label{expo_cdf}
\end{figure}

In general, the mean of an exponential distribution is $1/
\lambda$, so the mean of this distribution is 0.5.  The median is
$ln(2)/\lambda$, which is roughly 0.35.  \index{mean}
\index{median} \index{Australia} \index{Brisbane}

To see an example of a distribution that is approximately exponential,
we will look at the interarrival time of babies.
On December 18, 1997, 44 babies were born in a hospital in Brisbane,
Australia\footnote{This example is based on information and data from
  Dunn, ``A Simple Dataset for Demonstrating Common Distributions,''
  Journal of Statistics Education v.7, n.3 (1999).}.  The times of
birth for all 44 babies were reported in the local paper; you can
download the data from \url{http://thinkstats.com/babyboom.dat}.
\index{birth time}

Figure~\ref{interarrival_cdf} shows the CDF of the interarrival times
in minutes.  It seems to have the general shape of an exponential
distribution, but how can we tell?
\index{complementary CDF}
\index{CDF!complementary}
\index{CCDF}

One way is to plot the complementary CDF, $1-\CDF(x)$, on a
log-$y$ scale.  For data from an exponential distribution, the result
is a straight line.  Let's see why that works.

If you plot the complementary CDF (CCDF) of a dataset that you think is
exponential, you expect to see a function like:
%
\[ y \approx e^{-\lambda x} \]
%
Taking the log of both sides yields:

\[ log y \approx -\lambda x \]

So on a log-$y$ scale the CCDF is a straight line
with slope $-\lambda$.
\index{logarithmic scale}
\index{complementary CDF}
\index{CDF!complementary}
\index{CCDF}

\begin{figure}
% babyboom.py
\centerline{\includegraphics[height=2.5in]{figs/interarrivals.pdf}}
\caption{CDF of interarrival times}
\label{interarrival_cdf}
\end{figure}

\begin{figure}
% babyboom.py
\centerline{\includegraphics[height=2.5in]{figs/interarrivals_logy.pdf}}
\caption{CCDF of interarrival times.}
\label{interarrival_ccdf}
\end{figure}

Figure~\ref{interarrival_ccdf} shows the CCDF of the interarrivals
on a log-$y$ scale.  It is not exactly straight, which suggests that
the exponential distribution is only an approximation.  Most likely
the underlying assumption---that a birth is equally likely at any time
of day---is not exactly true.

\begin{exercise}
For small values of $n$, we don't expect an empirical distribution
to fit a continuous distribution exactly.  One way to evaluate
the quality of fit is to generate a sample from a continuous
distribution and see how well it matches the data.
\index{empirical distribution}
\index{distribution!empirical}
\index{random module}

The function {\tt expovariate} in the {\tt random} module generates
random values from an exponential distribution with a given value of
$\lambda$.  Use it to generate 44 values from an exponential
distribution with mean 32.6.  Plot the CCDF on a log-y~scale and
compare it to Figure~\ref{interarrival_ccdf}.
\index{pyplot}

Hint: You can use the function {\tt pyplot.yscale} to plot the y~axis
on a log scale.

% TODO: update this example

Or, if you use {\tt myplot}, the {\tt Cdf} function takes a boolean
option, {\tt complement}, that determines whether to plot the CDF or
CCDF, and string options, {\tt xscale} and {\tt yscale}, that
transform the axes; to plot a CCDF on a log-y~scale:
%
\begin{verbatim}
myplot.Cdf(cdf, complement=True, xscale='linear', yscale='log') 
\end{verbatim}

\end{exercise}

\begin{exercise}
Collect the birthdays of the students in your class, sort them, and
compute the interarrival times in days.  Plot the CDF of the interarrival
times and the CCDF on a log-y~scale.  Does it look like
an exponential distribution?
\index{exponential distribution}
\index{distribution!exponential}
\index{birthday}

\end{exercise}


\section{The Pareto distribution}
\index{Pareto distribution}
\index{distribution!Pareto}
\index{Pareto, Vilfredo}

The Pareto distribution is named after the economist Vilfredo Pareto,
who used it to describe the distribution of wealth (see
\url{http://wikipedia.org/wiki/Pareto_distribution}).  Since then, it has
been used to describe phenomena in the natural and social
sciences including sizes of cities and towns, sand particles and
meteorites, forest fires and earthquakes.
\index{CDF}

The CDF of the Pareto distribution is:
%
\[ CDF(x) = 1 - \left( \frac{x}{x_m} \right) ^{-\alpha} \]
%
The parameters $x_{m}$ and $\alpha$ determine the location and shape of
the distribution. $x_{m}$ is the minimum possible value.
Figure~\ref{pareto_cdf} shows the CDF of a Pareto distribution with
parameters $x_{m} = 0.5$ and $\alpha = 1$.
\index{parameter}

\begin{figure}
% continuous.py
\centerline{\includegraphics[height=2.5in]{figs/pareto_cdf.pdf}}
\caption{CDF of a Pareto distribution.}
\label{pareto_cdf}
\end{figure}

The median of this distribution is $x_m 2^{1/\alpha}$, which is 1, but
the 95th percentile is 10.  By contrast, the exponential distribution
with median 1 has 95th percentile of only 1.5.  \index{exponential
  distribution} \index{distribution!exponential} \index{median}
\index{logarithmic scale}

There is a simple visual test that indicates whether an empirical
distribution fits a Pareto distribution: on a log-log scale, the CCDF
looks like a straight line.
If you plot the CCDF of a sample from a Pareto distribution on a
linear scale, you expect to see a function like:
%
\[ y \approx \left( \frac{x}{x_m} \right) ^{-\alpha} \]
%
Taking the log of both sides yields:
%
\[ \log y \approx -\alpha(\log x - \log x_{m}) \]
%
So if you plot $\log y$ versus $log x$, it should look like a straight
line with slope $-\alpha$ and intercept
$\alpha~log x_{m}$.

\begin{exercise}
The {\tt random} module provides {\tt paretovariate},
which generates random values from a Pareto distribution.  It takes
a parameter for $\alpha$, but not $x_{m}$.  The
default value for $x_{m}$ is 1; you can generate a distribution
with a different parameter by multiplying by $x_{m}$.
\index{random module}
\index{Pareto distribution}
\index{distribution!Pareto}

Write a wrapper function named {\tt paretovariate} that takes
$\alpha$ and $x_{m}$ as parameters and uses {\tt
  random.paretovariate} to generate values from a two-parameter Pareto
distribution.
\index{parameter}

Use your function to generate a sample from a Pareto distribution.
Compute the CCDF and plot it on a log-log scale.  Is it a straight
line?  What is the slope?
\index{complementary CDF}
\index{CDF!complementary}
\index{CCDF}

\end{exercise}

\begin{exercise}
To get a feel for the Pareto distribution, imagine what the world
would be like if the distribution of human height were Pareto.
Choosing the parameters $x_{m} = 100$ cm and $\alpha = 1.7$, we
get a distribution with a reasonable minimum, 100 cm,
and median, 150 cm.
\index{height}

Generate 6 billion random values from this distribution.  What is the
mean of this sample?  What fraction of the population is shorter than
the mean?  How tall is the tallest person in Pareto World?
\index{Pareto World}

\end{exercise}

\begin{exercise}
Zipf's law is an observation about how often different words are used.
The most common words have very high frequencies, but there are many
unusual words, like ``hapaxlegomenon,'' that appear only a few times.
Zipf's law predicts that in a body of text, called a ``corpus,'' the
distribution of word frequencies is roughly Pareto.
\index{Pareto distribution}
\index{distribution!Pareto}
\index{Zipf's law}
\index{hapaxlegomenon}
\index{corpus}
\index{frequency}
\index{word frequency}

Find a large corpus, in any language, in electronic
format.  Count how many times each word appears.  Find the CCDF of the
word counts and plot it on a log-log scale.  Does Zipf's law hold?
What is the value of $\alpha$, approximately?
\index{complementary CDF}
\index{CDF!complementary}
\index{CCDF}

\end{exercise}

\begin{exercise}
\label{weibull}

The Weibull distribution is a generalization of the exponential
distribution that comes up in failure analysis
(see \url{http://wikipedia.org/wiki/Weibull_distribution}).  Its CDF is
%
\[ CDF(x) = 1 - e^{-(x / \lambda)^k} \]
%
Can you find a transformation that makes a Weibull distribution look
like a straight line?  What do the slope and intercept of the
line indicate?
\index{Weibull distribution}
\index{distribution!Weibull}
\index{exponential distribution}
\index{distribution!exponential}
\index{random module}

Use {\tt random.weibullvariate} to generate a sample from a
Weibull distribution and use it to test your transformation.

\end{exercise}


\section{The normal distribution}
\label{normal}
\index{normal distribution}
\index{distribution!normal}
\index{Gaussian distribution}
\index{distribution!Gaussian}

\newcommand{\erf}{\mathrm{erf}}

The normal distribution, also called Gaussian, is the most commonly
used because it describes so many phenomena, at least approximately.
It turns out that there is a good reason for its ubiquity, which we
will get to in Section~\ref{CLT}.
\index{error function}
\index{CDF}

The normal distribution has many properties that make it amenable for
analysis, but the CDF is not one of them.  Unlike the
other distributions we have looked at, there is no closed-form
expression for the normal CDF; the most common alternative is to write
it in terms of the {\bf error function}, which is a special function
written erf(x):
%
\[ CDF(x) = \frac{1}{2} \left[ 1 +
  \erf \left( \frac{x - \mu}{\sigma \sqrt{2}} \right) \right] \]
%
\[ \erf(x) = \frac{2}{\sqrt{\pi}} \int_{0}^x e^{-t^2} dt \]
%
The parameters $\mu$ and $\sigma$ determine the mean and standard
deviation of the distribution.
\index{parameter}
\index{{\tt erf.py}}

If these formulas make your eyes hurt, don't worry; they are easy to
implement in Python\footnote{As of Python 3.2, it is even easier; 
{\tt erf} is in the {\tt math} module.}.  There are many fast and
accurate ways to approximate $\erf(x)$.  You can download one of them
from \url{http://thinkstats.com/erf.py}, which provides functions named
{\tt erf} and {\tt NormalCdf}.

Figure~\ref{normal_cdf} shows the CDF of the normal distribution
with parameters $\mu = 2.0$ and $\sigma = 0.5$.  The sigmoid shape of
this curve is a recognizable characteristic of a normal distribution.

\begin{figure}
% continuous.py
\centerline{\includegraphics[height=2.5in]{figs/normal_cdf.pdf}}
\caption{CDF of a normal distribution.}
\label{normal_cdf}
\end{figure}

In the previous chapter we looked at the distribution of birth
weights in the NSFG.  Figure~\ref{nsfg_birthwgt_model} shows the
empirical CDF of weights for all live births and the CDF of
a normal distribution with the same mean and variance.
\index{National Survey of Family Growth}
\index{NSFG}
\index{birth weight}
\index{weight!birth}

\begin{figure}
% continuous.py
\centerline{\includegraphics[height=2.5in]{figs/nsfg_birthwgt_model.pdf}}
\caption{CDF of birth weights with a normal model.}
\label{nsfg_birthwgt_model}
\end{figure}

The normal distribution is a good model for this dataset.  A {\bf
  model} is a useful simplification.  In this case it is useful
because we can summarize the entire distribution with just two
numbers, $\mu = 116.5$ and $\sigma = 19.9$, and the resulting error
(difference between the model and the data) is small.
\index{model}
\index{percentile}

Below the 10th percentile there is a discrepancy between the data
and the model; there are more light babies than we would expect in
a normal distribution.  If we are interested in studying preterm
babies, it would be important to get this part of the distribution
right, so it might not be appropriate to use the normal
model.



\begin{exercise}
Plot the CDF of pregnancy lengths for all live births.  Does it
look like a normal distribution?
\index{pregnancy length}
\index{length!pregnancy}

Compute the mean and standard deviation of the sample and plot the normal
distribution with the same parameters.  Is the normal distribution a
good model for this data?  If you had to summarize this distribution
with two statistics, what statistics would you choose?

\end{exercise}


\section{Normal probability plot}
\index{normal probability plot}
\index{plot!normal probability}
\index{exponential distribution}
\index{distribution!exponential}
\index{Weibull distribution}
\index{distribution!Weibull}
\index{Pareto distribution}
\index{distribution!Pareto}

For the exponential, Pareto and Weibull distributions, there are
simple transformations we can use to test whether a continuous
distribution is a good model of a dataset.
\index{model}
\index{normal distribution}
\index{distribution!normal}
\index{Gaussian distribution}
\index{distribution!Gaussian}

For the normal distribution there is no such transformation, but there
is an alternative called a {\bf normal probability plot}.  It is based
on {\bf rankits}: if you generate $n$~values from a normal
distribution and sort them, the $k$th rankit is the mean of the
distribution for the $k$th value.
\index{rankit}

\begin{exercise}
Write a function called {\tt Sample} that generates 6 samples from a
normal distribution with $\mu = 0$ and $\sigma = 1$.  Sort and return
the values.

Write a function called {\tt Samples} that calls {\tt Sample} 1000 times and
returns a list of 1000 lists.

If you apply {\tt zip} to this list of lists, the result is 6 lists
with 1000 values in each.  Compute the mean of each of these lists
and print the results.  I predict that you will get something like
this:

\{-1.2672,   -0.6418,   -0.2016,   0.2016,   0.6418,   1.2672\}

If you increase the number of times you call {\tt Sample}, the
results should converge on these values.

\end{exercise}

% Algorithms for exact and approximate normal rank stats
% http://download.osgeo.org/grass/grass6_progman/as177_8c_source.html

Computing rankits exactly is moderately difficult, but there are
numerical methods for approximating them.  And there is a
quick-and-dirty method that is even easier to implement:

\begin{enumerate}

\item From a normal distribution with $\mu = 0$ and $\sigma = 1$,
generate a sample with the same size as your dataset and sort it.

\item Sort the values in the dataset.

\item Plot the sorted values from your dataset versus the random values.

\end{enumerate}

For large datasets, this method works well.
For smaller datasets, you can improve it by generating $m (n+1) - 1$
values from a normal distribution, where $n$ is the size of the
dataset and m~is a multiplier.  Then select every m th element,
starting with the m th.  

%Hint: use the Python slice operator.

This method works with other distributions as well, as long as
you know how to generate a random sample.

Figure~\ref{nsfg_birthwgt_normal} is a quick-and-dirty normal
probability plot for the birth weight data.
\index{birth weight}
\index{weight!birth}

\begin{figure}
% continuous.py
\centerline{\includegraphics[height=2.5in]{figs/nsfg_birthwgt_normal.pdf}}
\caption{Normal probability plot of birth weights.}
\label{nsfg_birthwgt_normal}
\end{figure}

The curvature in this plot suggests that there are
deviations from a normal distribution; nevertheless, it is a
good (enough) model for many purposes.
\index{model}

\begin{exercise}
Write a function called {\tt NormalPlot} that takes a sequence of
values and generates a normal probability plot.  You can download
a solution from \url{http://thinkstats.com/rankit.py}.
\index{normal distribution}
\index{distribution!normal}
\index{Gaussian distribution}
\index{distribution!Gaussian}
\index{{\tt rankit.py}}
\index{{\tt relay.py}}
\index{{\tt relay\_normal.py}}
\index{relay race}
\index{race!relay}

Use the running speeds from {\tt relay.py} to generate a normal
probability plot.  Is the normal distribution a good model for this
data?  You can download a solution from
\url{http://thinkstats.com/relay_normal.py}.

\end{exercise}


\section{The lognormal distribution}
\label{lognormal}
\index{lognormal distribution}
\index{distribution!lognormal}
\index{CDF}

If the logarithms of a set of values have a normal distribution, the
values have a {\bf lognormal} distribution.  The CDF of the lognormal
distribution is the same as the CDF of the normal distribution,
with log x~substituted for x.

\[ CDF_{lognormal}(x) = CDF_{normal}(log x) \]
 
The parameters of the lognormal distribution are usually denoted
$\mu$ and $\sigma$.  But remember that these parameters are {\em not}
the mean and standard deviation; the mean of a lognormal distribution
is $\exp(\mu + \sigma^2/2)$ and the standard deviation is
ugly\footnote{See \url{http://wikipedia.org/wiki/Log-normal_distribution}.}.
\index{parameter} \index{weight!adult} \index{adult weight}

It turns out that the distribution of weights for adults is
approximately lognormal\footnote{I was tipped off to this possibility by a
  comment (without citation) at
  \url{http://mathworld.wolfram.com/LogNormalDistribution.html}.
  Subsequently I found a paper that proposes the log transform and
  suggests a cause: Penman and Johnson, ``The Changing Shape of the
  Body Mass Index Distribution Curve in the Population,'' Preventing
  Chronic Disease, 2006 July; 3(3): A74.  Online
  at \url{http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1636707}.}.

The National Center for Chronic Disease
Prevention and Health Promotion conducts an annual survey as part of
the Behavioral Risk Factor Surveillance System
(BRFSS)\footnote{Centers for Disease Control and Prevention
  (CDC). Behavioral Risk Factor Surveillance System Survey
  Data. Atlanta, Georgia: U.S. Department of Health and Human
  Services, Centers for Disease Control and Prevention, 2008.}.  In
2008, they interviewed 414,509 respondents and asked about their
demographics, health and health risks.
\index{Behavioral Risk Factor Surveillance System}
\index{BRFSS}


\begin{figure}
% cumulative.py
\centerline{
\includegraphics[height=2.5in]{figs/brfss_weight_log.pdf}
}
\caption{CDF of adult weights (log
  transform).}
\label{brfss_weight_log}
\end{figure}

Among the data they collected are the weights in kilograms of
398,484 respondents.
Figure~\ref{brfss_weight_log} shows the distribution
of $\log w$, where $w$ is weight in kilograms, along with a normal
model.
\index{respondent}
\index{model}

The normal model is a good fit for the data, although the highest
weights exceed what we expect from the normal model even after the log
transform.  Since the distribution of $\log w$ fits a normal distribution, we
conclude that $w$ fits a lognormal distribution.
\index{normal distribution}
\index{distribution!normal}
\index{Gaussian distribution}
\index{distribution!Gaussian}
\index{lognormal distribution}
\index{distribution!lognormal}



\begin{exercise}
Download the BRFSS data from 
\url{http://thinkstats.com/CDBRFS08.ASC.gz}, and my code for reading it
from
\url{http://thinkstats.com/brfss.py}.  Run {\tt brfss.py} and confirm that
it prints summary statistics for a few of the variables.
\index{Behavioral Risk Factor Surveillance System}
\index{BRFSS}
\index{{\tt brfss.py}}
\index{{\tt brfss\_figs.py}}
\index{weight!adult}
\index{adult weight}

Write a program that reads adult weights from the BRFSS and
generates normal probability plots for $w$ and $\log w$.  You can
download a solution from \url{http://thinkstats.com/brfss_figs.py}.

\end{exercise}

\begin{exercise}
The distribution of populations for cities and towns has been proposed
as an example of a real-world phenomenon that can be described
with a Pareto distribution.
\index{Pareto distribution}
\index{distribution!Pareto}
\index{U.S.~Census Bureau}
\index{population}
\index{city size}

The U.S.~Census Bureau publishes data on the population of every
incorporated city and town in the United States.  I have written a
small program that downloads this data and stores it in a file.  You
can download it from \url{http://thinkstats.com/populations.py}.
\index{{\tt populations.py}}

\begin{enumerate}

\item Read over the program to make sure you know what it does; then
  run it to download and process the data.

\item Write a program that computes and plots the distribution of
  populations for the 14,593 cities and towns in the dataset.

\item Plot the CDF on linear and log-x scales so you can get a sense
  of the shape of the distribution.  Then plot the CCDF on a log-log
  scale to see if it has the characteristic shape of a Pareto
  distribution.
\index{complementary CDF}
\index{CDF!complementary}
\index{CCDF}

\item Try out the other transformations and plots in this chapter to
  see if there is a better model for this data.

\end{enumerate}

What conclusion do you draw about the distribution of sizes
for cities and towns?  You can download a solution from
\url{http://thinkstats.com/populations_cdf.py}.
\index{{\tt populations\_cdf.py}}

\end{exercise}


\begin{exercise}
\label{irs}

The Internal Revenue Service of the United States (IRS) provides data
about income taxes at \url{http://irs.gov/taxstats}.
\index{Internal Revenue Service}
\index{IRS}
\index{income}
\index{taxes}

One of their files, containing information about individual incomes
for 2008, is available from \url{http://thinkstats.com/08in11si.csv}.  I
converted it to a text format called CSV, which stands for
``comma-separated values;'' you can read it using the {\tt csv}
module.

Extract the distribution of incomes from this dataset.  Are any of
the continuous distributions in this chapter a good model of
the data?  You can download a solution from \url{http://thinkstats.com/irs.py}.
\index{{\tt irs.py}}

\end{exercise}


\section{Why model?}
\index{model}

At the beginning of this chapter I said that many real world phenomena
can be modeled with continuous distributions.  ``So,'' you might ask,
``what?''
\index{abstraction}

Like all models, continuous distributions are abstractions, which
means they leave out details that are considered irrelevant.
For example, an observed distribution might have measurement errors
or quirks that are specific to the sample; continuous models smooth
out these idiosyncrasies.
\index{smoothing}

Continuous models are also a form of data compression.  When a model
fits a dataset well, a small set of parameters can summarize a
large amount of data.
\index{parameter}
\index{compression}

It is sometimes surprising when data from a natural phenomenon fit a
continuous distribution, but these observations can lead to insight
into physical systems.  Sometimes we can explain why an observed
distribution has a particular form.  For example, Pareto distributions
are often the result of generative processes with positive feedback
(so-called preferential attachment processes: see
\url{http://wikipedia.org/wiki/Preferential_attachment}.).
\index{preferential attachment}
\index{generative process}
\index{Pareto distribution}
\index{distribution!Pareto}
\index{analysis}

Continuous distributions lend themselves to mathematical analysis, as
we will see in Chapter~\ref{operations}.





\end{document}



Case study ideas:

\begin{itemize}

\item Pitch tracking in Rock Band

\item Auto-Tune

\item JPEG compression

\item Image recognition in Fourier space (money)

\item Application of cepstrum?

\item Application of z transform -- digital control systems

\item tilt shift effect on a photo

\end{itemize}
